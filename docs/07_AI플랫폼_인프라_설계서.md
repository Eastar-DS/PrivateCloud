# AI 플랫폼 인프라 설계서

## 에이블스택(HCI) 기반 멀티테넌트 프라이빗 클라우드 인프라 설계

| 항목 | 내용 |
|------|------|
| 문서명 | AI 플랫폼 인프라 설계서 |
| 버전 | 1.0 |
| 작성일 | 2026-02-02 |
| 담당팀 | 컴퓨트/개발 팀 (GPU), 공통 (아키텍처) |

---

**목차**

1. [설계 개요](#1-설계-개요)
2. [AI 플랫폼 4계층 인프라 매핑](#2-ai-플랫폼-4계층-인프라-매핑)
3. [계층 1: 테넌트별 격리 환경](#3-계층-1-테넌트별-격리-환경)
4. [계층 2: 데이터 품질 게이트](#4-계층-2-데이터-품질-게이트)
5. [계층 3: 공용 AI 플랫폼](#5-계층-3-공용-ai-플랫폼)
6. [계층 4: 서비스 계층](#6-계층-4-서비스-계층)
7. [GPU 설계](#7-gpu-설계)
8. [AI 워크로드용 스토리지](#8-ai-워크로드용-스토리지)
9. [AI 워크로드용 네트워크](#9-ai-워크로드용-네트워크)
10. [통합 리소스 할당 계획](#10-통합-리소스-할당-계획)
11. [검증 시나리오](#11-검증-시나리오)

---

## 1. 설계 개요

### 1.1 목적

본 문서는 **공용 AI 플랫폼**을 지원하기 위한 인프라 설계를 정의한다. 프로젝트 개요서에서 정의한 4계층 AI 플랫폼 구조를 실제 인프라 자원에 매핑하고, 특히 AI 워크로드에 필수적인 **GPU 할당 설계**를 상세화한다.

### 1.2 설계 목표

| 목표 | 설명 | 검증 방법 |
|------|------|----------|
| **AI 워크로드 지원** | 학습/추론 워크로드를 위한 GPU 인프라 | GPU 할당 및 스케줄링 동작 |
| **테넌트 데이터 격리** | 테넌트 간 학습 데이터 완전 분리 | 데이터 접근 테스트 |
| **공용 모델 공유** | 품질 검증된 데이터로 공용 모델 학습 | 데이터 흐름 검증 |
| **성능 격리** | 테넌트 간 GPU/컴퓨트 자원 경합 방지 | 부하 테스트 |

### 1.3 참조 아키텍처

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                   AI 플랫폼 4계층 구조 (프로젝트 개요서 기준)                   │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   [계층 1: 테넌트별 격리 환경]                                              │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │   테넌트 A (A시청)      테넌트 B (B구청)      테넌트 C (C군청)       │  │
│   │   ┌───────────────┐    ┌───────────────┐    ┌───────────────┐       │  │
│   │   │ 민원 데이터    │    │ 민원 데이터    │    │ 민원 데이터    │       │  │
│   │   │ 테넌트 전용    │    │ 테넌트 전용    │    │ 테넌트 전용    │       │  │
│   │   │ 특화 모델     │    │ 특화 모델     │    │ 특화 모델     │       │  │
│   │   └───────┬───────┘    └───────┬───────┘    └───────┬───────┘       │  │
│   └───────────┼────────────────────┼────────────────────┼───────────────┘  │
│               └────────────────────┼────────────────────┘                  │
│                                    ▼                                        │
│   [계층 2: 데이터 품질 게이트] ─ 검증된 데이터만 공용 모델에 반영            │
│                                    │                                        │
│                                    ▼                                        │
│   [계층 3: 공용 AI 플랫폼] ─ 공용 모델 학습/서빙, GPU 풀 관리               │
│                                    │                                        │
│                                    ▼                                        │
│   [계층 4: 서비스 계층] ─ 테넌트 특화 모델 우선, 공용 모델 폴백             │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 2. AI 플랫폼 4계층 인프라 매핑

### 2.1 전체 아키텍처

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                    AI 플랫폼 인프라 전체 구성도                               │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                         서비스 계층 (계층 4)                         │   │
│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────────────────────┐ │   │
│  │  │ API Gateway │──│ 추론 라우터  │──│  Model Serving (Triton 등)  │ │   │
│  │  └─────────────┘  └─────────────┘  └─────────────────────────────┘ │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                    │                                        │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                      공용 AI 플랫폼 (계층 3)                         │   │
│  │  ┌───────────────────────────────────────────────────────────────┐ │   │
│  │  │                    공용 GPU 풀                                 │ │   │
│  │  │  ┌─────────┐  ┌─────────┐  ┌─────────┐  ┌─────────┐          │ │   │
│  │  │  │ GPU 0-1 │  │ GPU 2-3 │  │ GPU 4-5 │  │ GPU 6-7 │          │ │   │
│  │  │  │ 학습용  │  │ 학습용  │  │ 추론용  │  │ 추론용  │          │ │   │
│  │  │  └─────────┘  └─────────┘  └─────────┘  └─────────┘          │ │   │
│  │  └───────────────────────────────────────────────────────────────┘ │   │
│  │  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐   │   │
│  │  │ 공용 모델 저장소 │  │  학습 스케줄러   │  │  모델 레지스트리 │   │   │
│  │  └─────────────────┘  └─────────────────┘  └─────────────────┘   │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                    ▲                                        │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                    데이터 품질 게이트 (계층 2)                       │   │
│  │  ┌───────────────┐  ┌───────────────┐  ┌───────────────┐          │   │
│  │  │  데이터 검증   │  │  익명화 처리   │  │  품질 메트릭   │          │   │
│  │  │  파이프라인   │  │  파이프라인   │  │  대시보드     │          │   │
│  │  └───────────────┘  └───────────────┘  └───────────────┘          │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                    ▲                                        │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                    테넌트별 격리 환경 (계층 1)                       │   │
│  │                                                                     │   │
│  │   테넌트 A              테넌트 B              테넌트 C              │   │
│  │   ┌─────────────┐      ┌─────────────┐      ┌─────────────┐        │   │
│  │   │ 전용 GPU    │      │ 전용 GPU    │      │ 전용 GPU    │        │   │
│  │   │ (vGPU/할당) │      │ (vGPU/할당) │      │ (vGPU/할당) │        │   │
│  │   ├─────────────┤      ├─────────────┤      ├─────────────┤        │   │
│  │   │ 데이터 저장소│      │ 데이터 저장소│      │ 데이터 저장소│        │   │
│  │   │ (격리된 Pool)│      │ (격리된 Pool)│      │ (격리된 Pool)│        │   │
│  │   ├─────────────┤      ├─────────────┤      ├─────────────┤        │   │
│  │   │ 특화 모델   │      │ 특화 모델   │      │ 특화 모델   │        │   │
│  │   │ 학습/서빙   │      │ 학습/서빙   │      │ 학습/서빙   │        │   │
│  │   └─────────────┘      └─────────────┘      └─────────────┘        │   │
│  │                                                                     │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 2.2 계층별 인프라 구성 요약

| 계층 | 주요 컴포넌트 | VM 구성 | GPU 할당 | 네트워크 존 |
|------|-------------|---------|---------|------------|
| **계층 1** | 테넌트 데이터, 특화 모델 | 테넌트별 2~3대 | 테넌트 전용 vGPU | 테넌트 VLAN |
| **계층 2** | 데이터 검증, 익명화 | 공용 1~2대 | CPU만 (또는 소량 GPU) | AI 내부망 |
| **계층 3** | 공용 모델 학습/서빙 | 공용 2~4대 | 공용 GPU 풀 | AI 내부망 |
| **계층 4** | API Gateway, 추론 라우터 | 공용 2대 | 추론용 GPU | DMZ/서비스망 |

---

## 3. 계층 1: 테넌트별 격리 환경

### 3.1 설계 목표

- 테넌트 간 **학습 데이터 완전 격리**
- 테넌트별 **전용 GPU 자원** 보장
- **특화 모델** 학습 및 저장 환경 제공

### 3.2 인프라 구성

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                      테넌트별 격리 환경 상세 구성                             │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   테넌트 A (A시청) - VLAN 20                                               │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │                                                                     │  │
│   │   ┌───────────────┐    ┌───────────────┐    ┌───────────────┐      │  │
│   │   │ ai-a-train-01 │    │ ai-a-data-01  │    │ ai-a-serve-01 │      │  │
│   │   │ ───────────── │    │ ───────────── │    │ ───────────── │      │  │
│   │   │ 4vCPU/16GB    │    │ 2vCPU/8GB     │    │ 2vCPU/8GB     │      │  │
│   │   │ vGPU 8GB      │    │ -             │    │ vGPU 4GB      │      │  │
│   │   │               │    │               │    │               │      │  │
│   │   │ • 모델 학습   │    │ • 원본 데이터 │    │ • 모델 서빙   │      │  │
│   │   │ • 파인튜닝    │    │ • 전처리      │    │ • 추론 API    │      │  │
│   │   │ • 실험 관리   │    │ • 데이터 버전 │    │ • 캐싱        │      │  │
│   │   └───────────────┘    └───────────────┘    └───────────────┘      │  │
│   │                                                                     │  │
│   │   스토리지: tenant-a-ai-pool (500GB, 격리)                          │  │
│   │   ├── /data/raw       : 원본 데이터                                 │  │
│   │   ├── /data/processed : 전처리된 데이터                             │  │
│   │   ├── /models         : 학습된 모델                                 │  │
│   │   └── /experiments    : 실험 로그                                   │  │
│   │                                                                     │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   (테넌트 B, C도 동일 구조로 격리 구성)                                     │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 3.3 테넌트별 리소스 할당

| 테넌트 | VM 구성 | vCPU | Memory | GPU | 스토리지 |
|--------|---------|------|--------|-----|---------|
| **테넌트 A** | 학습1 + 데이터1 + 서빙1 | 8 | 32GB | vGPU 12GB | 500GB |
| **테넌트 B** | 학습1 + 데이터1 + 서빙1 | 8 | 32GB | vGPU 12GB | 500GB |
| **테넌트 C** | 학습1 + 서빙1 | 6 | 24GB | vGPU 8GB | 300GB |

### 3.4 데이터 격리 정책

```yaml
# 테넌트 데이터 격리 정책
tenant_data_isolation:
  storage:
    # 테넌트별 전용 Ceph Pool
    - pool: tenant-a-ai-data
      access: [client.tenant-a]
      quota: 500GB
    - pool: tenant-b-ai-data
      access: [client.tenant-b]
      quota: 500GB
    - pool: tenant-c-ai-data
      access: [client.tenant-c]
      quota: 300GB

  network:
    # 테넌트 간 직접 통신 차단
    - from: tenant-a
      to: tenant-b
      action: DENY
    # 공용 계층으로만 데이터 전송 가능
    - from: tenant-a
      to: data-quality-gate
      action: ALLOW
      ports: [443]  # HTTPS만 허용

  encryption:
    at_rest: AES-256
    in_transit: TLS 1.3
    key_management: per-tenant  # 테넌트별 암호화 키
```

---

## 4. 계층 2: 데이터 품질 게이트

### 4.1 설계 목표

- 테넌트 데이터의 **품질 검증** 후 공용 모델 학습에 반영
- **개인정보 익명화** 처리
- 데이터 **출처 추적** 및 감사

### 4.2 인프라 구성

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                      데이터 품질 게이트 인프라                                │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   AI 내부망 (VLAN 50)                                                       │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │                                                                     │  │
│   │   ┌─────────────────────────┐    ┌─────────────────────────┐       │  │
│   │   │    dqg-validator-01     │    │    dqg-processor-01     │       │  │
│   │   │    ─────────────────    │    │    ─────────────────    │       │  │
│   │   │    4vCPU / 16GB         │    │    4vCPU / 16GB         │       │  │
│   │   │    (GPU 선택적)         │    │    (GPU 선택적)         │       │  │
│   │   │                         │    │                         │       │  │
│   │   │    • 데이터 스키마 검증 │    │    • PII 탐지/마스킹    │       │  │
│   │   │    • 품질 점수 산정     │    │    • 익명화 처리        │       │  │
│   │   │    • 이상치 탐지        │    │    • 데이터 변환        │       │  │
│   │   │    • 중복 제거          │    │    • 라벨 표준화        │       │  │
│   │   │                         │    │                         │       │  │
│   │   └───────────┬─────────────┘    └─────────────┬───────────┘       │  │
│   │               │                                │                    │  │
│   │               ▼                                ▼                    │  │
│   │   ┌─────────────────────────────────────────────────────────────┐  │  │
│   │   │                    품질 게이트 스토리지                      │  │  │
│   │   │    ┌──────────────┐  ┌──────────────┐  ┌──────────────┐    │  │  │
│   │   │    │  스테이징    │  │  승인 대기   │  │  승인 완료   │    │  │  │
│   │   │    │  (검증 전)   │  │  (검토 중)   │  │  (공용 전송) │    │  │  │
│   │   │    └──────────────┘  └──────────────┘  └──────────────┘    │  │  │
│   │   └─────────────────────────────────────────────────────────────┘  │  │
│   │                                                                     │  │
│   │   데이터 흐름:                                                      │  │
│   │   테넌트 → [스테이징] → [검증] → [익명화] → [승인] → 공용 플랫폼   │  │
│   │                                                                     │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 4.3 VM 구성

| VM 이름 | 역할 | 스펙 | GPU | 용도 |
|---------|------|------|-----|------|
| **dqg-validator-01** | 데이터 검증 | 4vCPU/16GB | 선택적 | 스키마 검증, 품질 점수, 이상치 탐지 |
| **dqg-processor-01** | 데이터 처리 | 4vCPU/16GB | 선택적 | PII 탐지, 익명화, 변환 |

### 4.4 데이터 흐름 정책

```yaml
# 데이터 품질 게이트 정책
data_quality_gate:
  # 데이터 수신 정책
  ingestion:
    sources:
      - tenant-a: api-endpoint  # REST API로 데이터 제출
      - tenant-b: api-endpoint
      - tenant-c: api-endpoint
    max_batch_size: 10GB
    allowed_formats: [parquet, csv, json]

  # 검증 규칙
  validation:
    schema_check: required
    quality_score_threshold: 0.8  # 80% 이상만 통과
    duplicate_check: enabled
    outlier_detection: enabled

  # 익명화 처리
  anonymization:
    pii_detection: enabled
    methods:
      - name: masking
        fields: [name, phone, email]
      - name: generalization
        fields: [address, age]
      - name: k-anonymity
        k_value: 5

  # 승인 프로세스
  approval:
    auto_approve: false  # 수동 승인 필요
    approvers: [platform-admin]
    retention_days: 30  # 미승인 데이터 30일 후 삭제

  # 감사 로깅
  audit:
    log_all_submissions: true
    log_transformations: true
    data_lineage: enabled
```

---

## 5. 계층 3: 공용 AI 플랫폼

### 5.1 설계 목표

- **공용 모델** 학습을 위한 GPU 풀 관리
- 여러 테넌트의 승인된 데이터로 **통합 학습**
- 학습된 모델의 **버전 관리** 및 배포

### 5.2 인프라 구성

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        공용 AI 플랫폼 인프라                                  │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   AI 내부망 (VLAN 50)                                                       │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │                                                                     │  │
│   │   ┌─────────────────────────────────────────────────────────────┐  │  │
│   │   │                    공용 GPU 클러스터                         │  │  │
│   │   │                                                             │  │  │
│   │   │   ┌─────────────────┐    ┌─────────────────┐               │  │  │
│   │   │   │ ai-train-01     │    │ ai-train-02     │               │  │  │
│   │   │   │ ─────────────── │    │ ─────────────── │               │  │  │
│   │   │   │ 8vCPU / 64GB    │    │ 8vCPU / 64GB    │               │  │  │
│   │   │   │ GPU x2 (학습)   │    │ GPU x2 (학습)   │               │  │  │
│   │   │   │                 │    │                 │               │  │  │
│   │   │   │ • 분산 학습     │    │ • 분산 학습     │               │  │  │
│   │   │   │ • 대규모 배치   │    │ • 대규모 배치   │               │  │  │
│   │   │   └─────────────────┘    └─────────────────┘               │  │  │
│   │   │                                                             │  │  │
│   │   │   ┌─────────────────┐    ┌─────────────────┐               │  │  │
│   │   │   │ ai-infer-01     │    │ ai-infer-02     │               │  │  │
│   │   │   │ ─────────────── │    │ ─────────────── │               │  │  │
│   │   │   │ 4vCPU / 32GB    │    │ 4vCPU / 32GB    │               │  │  │
│   │   │   │ GPU x1 (추론)   │    │ GPU x1 (추론)   │               │  │  │
│   │   │   │                 │    │                 │               │  │  │
│   │   │   │ • 모델 서빙     │    │ • 모델 서빙     │               │  │  │
│   │   │   │ • 배치 추론     │    │ • 배치 추론     │               │  │  │
│   │   │   └─────────────────┘    └─────────────────┘               │  │  │
│   │   │                                                             │  │  │
│   │   └─────────────────────────────────────────────────────────────┘  │  │
│   │                                                                     │  │
│   │   ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐   │  │
│   │   │ ai-scheduler-01 │  │ ai-registry-01  │  │ ai-storage-01   │   │  │
│   │   │ ─────────────── │  │ ─────────────── │  │ ─────────────── │   │  │
│   │   │ 2vCPU / 8GB     │  │ 2vCPU / 8GB     │  │ 4vCPU / 16GB    │   │  │
│   │   │                 │  │                 │  │                 │   │  │
│   │   │ • 작업 스케줄링 │  │ • 모델 저장     │  │ • 학습 데이터   │   │  │
│   │   │ • GPU 할당      │  │ • 버전 관리     │  │ • 체크포인트    │   │  │
│   │   │ • 큐 관리       │  │ • 메타데이터    │  │ • 로그 저장     │   │  │
│   │   └─────────────────┘  └─────────────────┘  └─────────────────┘   │  │
│   │                                                                     │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 5.3 VM 구성

| VM 이름 | 역할 | 스펙 | GPU | 용도 |
|---------|------|------|-----|------|
| **ai-train-01/02** | 학습 서버 | 8vCPU/64GB | 2 GPU | 공용 모델 분산 학습 |
| **ai-infer-01/02** | 추론 서버 | 4vCPU/32GB | 1 GPU | 공용 모델 서빙 |
| **ai-scheduler-01** | 스케줄러 | 2vCPU/8GB | - | 작업 큐, GPU 할당 |
| **ai-registry-01** | 모델 레지스트리 | 2vCPU/8GB | - | MLflow, 모델 버전 관리 |
| **ai-storage-01** | 데이터 저장소 | 4vCPU/16GB | - | 학습 데이터, 체크포인트 |

### 5.4 학습 파이프라인

```yaml
# 공용 모델 학습 파이프라인
training_pipeline:
  # 데이터 소스
  data_sources:
    - approved_data_pool  # 품질 게이트 통과 데이터

  # 학습 작업 정의
  job_types:
    - name: full_training
      description: 전체 데이터 재학습
      schedule: weekly
      gpu_requirement: 4
      estimated_duration: 24h

    - name: incremental_training
      description: 신규 데이터 증분 학습
      schedule: daily
      gpu_requirement: 2
      estimated_duration: 4h

    - name: fine_tuning
      description: 특정 도메인 파인튜닝
      trigger: on_demand
      gpu_requirement: 2
      estimated_duration: 2h

  # 모델 배포
  deployment:
    auto_deploy: false  # 수동 승인 후 배포
    canary_percentage: 10  # 10% 카나리 배포
    rollback_threshold: 0.95  # 성능 95% 미만 시 롤백
```

---

## 6. 계층 4: 서비스 계층

### 6.1 설계 목표

- 테넌트 요청에 대한 **지능형 라우팅**
- **테넌트 특화 모델 우선**, 공용 모델 폴백
- **고가용성** 추론 서비스 제공

### 6.2 인프라 구성

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        서비스 계층 인프라                                    │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   [인터넷/사용자]                                                           │
│         │                                                                   │
│         ▼                                                                   │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  DMZ (VLAN 10)                                                      │  │
│   │  ┌─────────────────────────────────────────────────────────────┐   │  │
│   │  │                    ai-gateway-01/02                          │   │  │
│   │  │                    (L7 Load Balancer)                        │   │  │
│   │  │                                                              │   │  │
│   │  │   • SSL 종료       • Rate Limiting    • 인증/인가            │   │  │
│   │  │   • 요청 라우팅    • API 버전 관리    • 로깅                 │   │  │
│   │  │                                                              │   │  │
│   │  └──────────────────────────┬───────────────────────────────────┘   │  │
│   └─────────────────────────────┼───────────────────────────────────────┘  │
│                                 │                                          │
│   ┌─────────────────────────────┼───────────────────────────────────────┐  │
│   │  서비스망 (VLAN 55)         │                                       │  │
│   │                             ▼                                       │  │
│   │  ┌─────────────────────────────────────────────────────────────┐   │  │
│   │  │                    ai-router-01/02                           │   │  │
│   │  │                    (추론 라우터)                              │   │  │
│   │  │                                                              │   │  │
│   │  │   라우팅 로직:                                                │   │  │
│   │  │   1. 테넌트 ID 확인                                          │   │  │
│   │  │   2. 테넌트 특화 모델 존재 여부 확인                          │   │  │
│   │  │   3. 특화 모델 있음 → 테넌트 서빙 VM                          │   │  │
│   │  │   4. 특화 모델 없음 → 공용 모델 서빙                          │   │  │
│   │  │                                                              │   │  │
│   │  └───────────┬─────────────────────────────────┬───────────────┘   │  │
│   │              │                                 │                    │  │
│   │              ▼                                 ▼                    │  │
│   │   ┌─────────────────────┐         ┌─────────────────────┐         │  │
│   │   │  테넌트 특화 모델   │         │   공용 모델 서빙    │         │  │
│   │   │  (계층 1 서빙 VM)   │         │  (계층 3 추론 VM)   │         │  │
│   │   │                     │         │                     │         │  │
│   │   │  ai-a-serve-01      │         │  ai-infer-01/02     │         │  │
│   │   │  ai-b-serve-01      │         │                     │         │  │
│   │   │  ai-c-serve-01      │         │                     │         │  │
│   │   └─────────────────────┘         └─────────────────────┘         │  │
│   │                                                                     │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 6.3 VM 구성

| VM 이름 | 역할 | 스펙 | GPU | 위치 |
|---------|------|------|-----|------|
| **ai-gateway-01/02** | API Gateway | 2vCPU/4GB | - | DMZ |
| **ai-router-01/02** | 추론 라우터 | 2vCPU/8GB | - | 서비스망 |

### 6.4 라우팅 정책

```yaml
# 추론 라우팅 정책
inference_routing:
  # 기본 라우팅 규칙
  default_rule:
    priority: tenant_model_first  # 테넌트 모델 우선
    fallback: shared_model        # 폴백: 공용 모델

  # 테넌트별 라우팅
  tenant_routes:
    tenant-a:
      primary: ai-a-serve-01:8080
      fallback: ai-infer-01:8080
      health_check: /health
      timeout: 30s

    tenant-b:
      primary: ai-b-serve-01:8080
      fallback: ai-infer-01:8080
      health_check: /health
      timeout: 30s

    tenant-c:
      primary: ai-c-serve-01:8080
      fallback: ai-infer-02:8080  # 부하 분산
      health_check: /health
      timeout: 30s

  # 장애 대응
  failover:
    retry_count: 3
    circuit_breaker:
      threshold: 5  # 5회 실패 시 차단
      reset_timeout: 60s

  # 부하 분산
  load_balancing:
    algorithm: round_robin
    sticky_session: false
```

---

## 7. GPU 설계

### 7.1 GPU 가상화 전략

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        GPU 가상화 옵션 비교                                  │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  옵션 1: GPU Passthrough (전용 할당)                                │  │
│   │  ──────────────────────────────────────────────────────────────    │  │
│   │                                                                     │  │
│   │   물리 GPU 1개 ────────► VM 1개 (1:1 매핑)                         │  │
│   │                                                                     │  │
│   │   장점: 최대 성능, 드라이버 호환성                                  │  │
│   │   단점: 자원 낭비 가능, 유연성 부족                                 │  │
│   │   적합: 고성능 학습, 단일 대형 모델                                 │  │
│   │                                                                     │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  옵션 2: vGPU (NVIDIA GRID)                                         │  │
│   │  ──────────────────────────────────────────────────────────────    │  │
│   │                                                                     │  │
│   │   물리 GPU 1개 ────┬───► vGPU 8GB (VM 1)                           │  │
│   │                    ├───► vGPU 8GB (VM 2)                           │  │
│   │                    └───► vGPU 8GB (VM 3)                           │  │
│   │                                                                     │  │
│   │   장점: 자원 공유, 유연한 할당, 멀티테넌시 적합                     │  │
│   │   단점: 라이선스 비용, 약간의 오버헤드                              │  │
│   │   적합: 멀티테넌트 환경, 소규모 학습/추론                           │  │
│   │                                                                     │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  옵션 3: MIG (Multi-Instance GPU) - A100/H100                       │  │
│   │  ──────────────────────────────────────────────────────────────    │  │
│   │                                                                     │  │
│   │   A100 80GB ────┬───► MIG 1g.10gb (인스턴스 1)                     │  │
│   │                 ├───► MIG 2g.20gb (인스턴스 2)                     │  │
│   │                 └───► MIG 4g.40gb (인스턴스 3)                     │  │
│   │                                                                     │  │
│   │   장점: 하드웨어 수준 격리, 성능 보장, 메모리 격리                  │  │
│   │   단점: 최신 GPU만 지원, 분할 크기 제한                             │  │
│   │   적합: 엔터프라이즈 멀티테넌트                                     │  │
│   │                                                                     │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  옵션 4: Time-Slicing (시분할 공유)                                 │  │
│   │  ──────────────────────────────────────────────────────────────    │  │
│   │                                                                     │  │
│   │   물리 GPU 1개 ─── 시간 분할 ───► VM 1 (33%) / VM 2 (33%) / VM 3   │  │
│   │                                                                     │  │
│   │   장점: 추가 비용 없음, 구현 간단                                   │  │
│   │   단점: 메모리 격리 없음, 성능 변동                                 │  │
│   │   적합: 개발/테스트, 추론 워크로드                                  │  │
│   │                                                                     │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 7.2 본 프로젝트 GPU 전략

| 구분 | 가상화 방식 | 적용 대상 | 선택 근거 |
|------|-----------|----------|----------|
| **테넌트 전용** | vGPU (권장) 또는 MIG | 테넌트 학습/추론 VM | 멀티테넌트 격리, 유연한 할당 |
| **공용 학습** | GPU Passthrough | 공용 학습 서버 | 최대 성능 필요 |
| **공용 추론** | vGPU 또는 Time-Slicing | 공용 추론 서버 | 비용 효율, 동시 요청 처리 |
| **데모 환경** | Time-Slicing | 전체 (GPU 없는 경우) | 실제 GPU 없이 구조 검증 |

### 7.3 GPU 할당 설계

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        GPU 할당 계획 (엔터프라이즈 기준)                       │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   물리 GPU 구성 (예: NVIDIA A100 40GB x 8)                                  │
│                                                                             │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  GPU 0-1: 테넌트 전용 풀                                            │  │
│   │  ─────────────────────────────────────────────────────────────────  │  │
│   │                                                                     │  │
│   │  GPU 0 (40GB)                    GPU 1 (40GB)                       │  │
│   │  ┌───────────────────────┐      ┌───────────────────────┐          │  │
│   │  │ vGPU-A: 12GB (Tenant A)│      │ vGPU-D: 12GB (Tenant A)│          │  │
│   │  │ vGPU-B: 12GB (Tenant B)│      │ vGPU-E: 12GB (Tenant B)│          │  │
│   │  │ vGPU-C: 12GB (Tenant C)│      │ vGPU-F: 12GB (Tenant C)│          │  │
│   │  │ (여유: 4GB)            │      │ (여유: 4GB)            │          │  │
│   │  └───────────────────────┘      └───────────────────────┘          │  │
│   │                                                                     │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  GPU 2-5: 공용 학습 풀                                              │  │
│   │  ─────────────────────────────────────────────────────────────────  │  │
│   │                                                                     │  │
│   │  ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐                  │  │
│   │  │ GPU 2   │ │ GPU 3   │ │ GPU 4   │ │ GPU 5   │                  │  │
│   │  │ (40GB)  │ │ (40GB)  │ │ (40GB)  │ │ (40GB)  │                  │  │
│   │  │         │ │         │ │         │ │         │                  │  │
│   │  │ 분산    │ │ 분산    │ │ 분산    │ │ 분산    │                  │  │
│   │  │ 학습    │ │ 학습    │ │ 학습    │ │ 학습    │                  │  │
│   │  └─────────┘ └─────────┘ └─────────┘ └─────────┘                  │  │
│   │                                                                     │  │
│   │  Passthrough 할당 (ai-train-01: GPU 2,3 / ai-train-02: GPU 4,5)    │  │
│   │                                                                     │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  GPU 6-7: 공용 추론 풀                                              │  │
│   │  ─────────────────────────────────────────────────────────────────  │  │
│   │                                                                     │  │
│   │  GPU 6 (40GB)                    GPU 7 (40GB)                       │  │
│   │  ┌───────────────────────┐      ┌───────────────────────┐          │  │
│   │  │ ai-infer-01           │      │ ai-infer-02           │          │  │
│   │  │ 추론 서빙 전용        │      │ 추론 서빙 전용        │          │  │
│   │  │                       │      │                       │          │  │
│   │  │ vGPU 또는 Passthrough │      │ vGPU 또는 Passthrough │          │  │
│   │  └───────────────────────┘      └───────────────────────┘          │  │
│   │                                                                     │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 7.4 테넌트별 GPU 쿼터

```yaml
# GPU 쿼터 정책
gpu_quotas:
  # 테넌트별 쿼터
  tenants:
    tenant-a:
      dedicated_memory: 24GB  # vGPU 2개 (12GB x 2)
      max_concurrent_jobs: 2
      priority: normal
      burst_allowed: true     # 유휴 시 추가 사용 허용
      burst_limit: 40GB       # 버스트 최대

    tenant-b:
      dedicated_memory: 24GB
      max_concurrent_jobs: 2
      priority: normal
      burst_allowed: true
      burst_limit: 40GB

    tenant-c:
      dedicated_memory: 16GB  # vGPU 2개 (8GB x 2)
      max_concurrent_jobs: 1
      priority: normal
      burst_allowed: true
      burst_limit: 24GB

  # 공용 풀
  shared_pool:
    training:
      total_gpus: 4
      gpu_memory: 160GB  # 40GB x 4
      max_job_duration: 48h
      queue_policy: fifo_with_priority

    inference:
      total_gpus: 2
      gpu_memory: 80GB   # 40GB x 2
      reserved_for_serving: 60%
      batch_processing: 40%
```

### 7.5 GPU 스케줄링

```yaml
# GPU 스케줄러 설정
gpu_scheduler:
  # 스케줄링 알고리즘
  algorithm: fair_share_with_priority

  # 작업 우선순위
  priority_classes:
    - name: critical
      weight: 100
      preemption: allowed
      examples: [production_inference]

    - name: high
      weight: 50
      preemption: allowed
      examples: [scheduled_training]

    - name: normal
      weight: 10
      preemption: not_allowed
      examples: [tenant_training]

    - name: low
      weight: 1
      preemption: not_allowed
      examples: [experiments, development]

  # 작업 큐 관리
  queue:
    max_queue_size: 100
    max_wait_time: 24h
    auto_scale: false  # 프라이빗 환경

  # 리소스 예약
  reservations:
    # 테넌트 예약 (보장 자원)
    - name: tenant-a-reserved
      gpu_memory: 12GB
      time_window: always

    # 배치 학습 예약
    - name: nightly-training
      gpu_count: 4
      time_window: "02:00-06:00"

  # 유휴 자원 활용
  idle_resource:
    enable_burst: true
    burst_priority: low
    reclaim_grace_period: 5m
```

### 7.6 GPU 모니터링

```yaml
# GPU 모니터링 메트릭
gpu_monitoring:
  metrics:
    # NVIDIA DCGM 메트릭
    - name: gpu_utilization
      description: GPU 코어 사용률
      alert_threshold: 90%

    - name: gpu_memory_used
      description: GPU 메모리 사용량
      alert_threshold: 90%

    - name: gpu_temperature
      description: GPU 온도
      alert_threshold: 80°C

    - name: gpu_power_usage
      description: GPU 전력 사용량
      alert_threshold: 300W

    - name: tensor_core_utilization
      description: Tensor 코어 활용률
      # ML 학습 효율성 지표

    - name: pcie_bandwidth
      description: PCIe 대역폭 사용률
      # 데이터 전송 병목 감지

  # 대시보드
  dashboards:
    - name: GPU Overview
      panels:
        - gpu_utilization_by_tenant
        - gpu_memory_by_pool
        - active_training_jobs
        - inference_latency

    - name: GPU Health
      panels:
        - temperature_heatmap
        - power_consumption
        - error_counts

  # 알림 규칙
  alerts:
    - name: GPU_OOM
      condition: gpu_memory_used > 95%
      severity: critical
      action: notify_and_throttle

    - name: GPU_Thermal
      condition: gpu_temperature > 85°C
      severity: warning
      action: notify_and_reduce_load

    - name: GPU_Idle
      condition: gpu_utilization < 5% for 1h
      severity: info
      action: notify_for_optimization
```

---

## 8. AI 워크로드용 스토리지

### 8.1 스토리지 요구사항

| 데이터 유형 | 특성 | 요구사항 |
|------------|------|----------|
| **학습 데이터** | 대용량, 순차 읽기 | 높은 처리량 (GB/s) |
| **모델 체크포인트** | 중간 크기, 빈번한 쓰기 | 빠른 쓰기 속도 |
| **모델 저장소** | 다양한 크기, 빈번한 읽기 | 낮은 지연시간 |
| **로그/메트릭** | 작은 크기, 연속 쓰기 | 안정적 쓰기 |

### 8.2 AI 전용 스토리지 풀

```yaml
# AI 워크로드 스토리지 설계
ai_storage:
  pools:
    # 학습 데이터 풀 (Hot)
    - name: ai-training-data
      type: CephFS
      tier: hot_ssd
      capacity: 2TB
      performance:
        read_throughput: 2GB/s
        write_throughput: 1GB/s
      features:
        - parallel_read  # 분산 학습 지원
        - compression: lz4

    # 모델 저장소 풀
    - name: ai-model-registry
      type: RBD
      tier: hot_ssd
      capacity: 500GB
      performance:
        iops: 10000
        latency: < 1ms
      features:
        - snapshot_support
        - versioning

    # 체크포인트 풀
    - name: ai-checkpoints
      type: CephFS
      tier: warm_ssd
      capacity: 1TB
      retention: 7d  # 자동 정리
      features:
        - fast_write
        - auto_cleanup

    # 아카이브 풀
    - name: ai-archive
      type: RGW
      tier: cold_hdd
      capacity: 5TB
      features:
        - erasure_coding: ec_4_2
        - lifecycle:
            - transition_days: 90
              action: compress
```

### 8.3 테넌트별 AI 스토리지

| 테넌트 | 학습 데이터 | 모델 저장 | 체크포인트 | 합계 |
|--------|-----------|----------|-----------|------|
| **테넌트 A** | 200GB | 50GB | 50GB | 300GB |
| **테넌트 B** | 200GB | 50GB | 50GB | 300GB |
| **테넌트 C** | 150GB | 30GB | 30GB | 210GB |
| **공용** | 500GB | 200GB | 200GB | 900GB |

---

## 9. AI 워크로드용 네트워크

### 9.1 AI 네트워크 토폴로지

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        AI 네트워크 구성                                      │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  VLAN 50: AI 내부망                                                 │  │
│   │  ─────────────────────────────────────────────────────────────────  │  │
│   │                                                                     │  │
│   │  대역: 10.0.5.0/24                                                  │  │
│   │  대역폭: 25Gbps (GPU 클러스터 간)                                    │  │
│   │  용도: 분산 학습, 모델 동기화, 내부 통신                             │  │
│   │                                                                     │  │
│   │  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐             │  │
│   │  │ ai-train-01 │◄──►│ ai-train-02 │◄──►│ ai-infer-*  │             │  │
│   │  │ 10.0.5.10   │    │ 10.0.5.11   │    │ 10.0.5.20-21│             │  │
│   │  └─────────────┘    └─────────────┘    └─────────────┘             │  │
│   │                                                                     │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  VLAN 55: AI 서비스망                                               │  │
│   │  ─────────────────────────────────────────────────────────────────  │  │
│   │                                                                     │  │
│   │  대역: 10.0.5.128/25                                                │  │
│   │  용도: 추론 요청, API 통신                                          │  │
│   │                                                                     │  │
│   │  ┌─────────────┐    ┌─────────────┐                                │  │
│   │  │ ai-router   │◄──►│ ai-gateway  │◄── 외부 요청                   │  │
│   │  │ 10.0.5.130  │    │ 10.0.5.131  │                                │  │
│   │  └─────────────┘    └─────────────┘                                │  │
│   │                                                                     │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  VLAN 60: GPU 스토리지망 (기존 스토리지망과 분리 또는 공유)          │  │
│   │  ─────────────────────────────────────────────────────────────────  │  │
│   │                                                                     │  │
│   │  대역: 10.0.6.0/24                                                  │  │
│   │  대역폭: 100Gbps (학습 데이터 I/O)                                  │  │
│   │  용도: 학습 데이터 읽기, 체크포인트 저장                            │  │
│   │                                                                     │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 9.2 추가 VLAN 할당

| VLAN ID | 네트워크 존 | IP 대역 | 용도 |
|---------|-----------|---------|------|
| **50** | AI 내부망 | 10.0.5.0/25 | 분산 학습, 모델 동기화 |
| **55** | AI 서비스망 | 10.0.5.128/25 | 추론 API, 라우팅 |
| **60** | GPU 스토리지망 | 10.0.6.0/24 | 학습 데이터 I/O |

**총 VLAN 사용: 10개** (기존 7개 + AI 3개)

---

## 10. 통합 리소스 할당 계획

### 10.1 데모 환경 전체 구성

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                    데모 환경 AI 플랫폼 VM 구성 (총 ~18대)                     │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   계층 1: 테넌트별 격리 환경 (9대)                                          │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  테넌트 A          테넌트 B          테넌트 C                       │  │
│   │  ───────────────  ───────────────  ───────────────                 │  │
│   │  ai-a-train-01    ai-b-train-01    ai-c-train-01                   │  │
│   │  ai-a-data-01     ai-b-data-01     ai-c-serve-01                   │  │
│   │  ai-a-serve-01    ai-b-serve-01                                    │  │
│   │                                                                     │  │
│   │  소계: 8vCPU/32GB  8vCPU/32GB      6vCPU/24GB                      │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   계층 2: 데이터 품질 게이트 (2대)                                          │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  dqg-validator-01    dqg-processor-01                               │  │
│   │  4vCPU/16GB          4vCPU/16GB                                     │  │
│   │                                                                     │  │
│   │  소계: 8vCPU/32GB                                                   │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   계층 3: 공용 AI 플랫폼 (5대)                                              │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  ai-train-01     ai-train-02     ai-infer-01    ai-infer-02        │  │
│   │  8vCPU/64GB      8vCPU/64GB      4vCPU/32GB     4vCPU/32GB         │  │
│   │  GPU x2          GPU x2          GPU x1         GPU x1             │  │
│   │                                                                     │  │
│   │  ai-scheduler-01  ai-registry-01  ai-storage-01                    │  │
│   │  2vCPU/8GB        2vCPU/8GB       4vCPU/16GB                       │  │
│   │                                                                     │  │
│   │  소계: 32vCPU/224GB + GPU 6개                                       │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   계층 4: 서비스 계층 (2대)                                                 │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  ai-gateway-01      ai-router-01                                    │  │
│   │  2vCPU/4GB          2vCPU/8GB                                       │  │
│   │                                                                     │  │
│   │  소계: 4vCPU/12GB                                                   │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   ═══════════════════════════════════════════════════════════════════════  │
│   총계: ~52vCPU / ~300GB Memory / GPU 6개 (엔터프라이즈 기준)              │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 10.2 데모 환경 최소 구성 (GPU 없는 ��우)

실제 GPU가 없는 경우, CPU 기반으로 구조만 검증:

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                    데모 환경 최소 구성 (GPU 없음, ~12대)                      │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   계층 1: 테넌트별 (6대, GPU 없이 CPU만)                                    │
│   ─────────────────────────────────────────────────────────────────────    │
│   ai-a-ml-01 (2vCPU/8GB)    : 학습+서빙 통합                               │
│   ai-a-data-01 (2vCPU/4GB)  : 데이터                                       │
│   ai-b-ml-01 (2vCPU/8GB)    : 학습+서빙 통합                               │
│   ai-b-data-01 (2vCPU/4GB)  : 데이터                                       │
│   ai-c-ml-01 (2vCPU/8GB)    : 학습+서빙 통합                               │
│   (데이터는 ml과 통합)                                                     │
│                                                                             │
│   계층 2: 데이터 품질 게이트 (1대)                                          │
│   ─────────────────────────────────────────────────────────────────────    │
│   dqg-01 (2vCPU/8GB)        : 검증+처리 통합                               │
│                                                                             │
│   계층 3: 공용 AI 플랫폼 (3대)                                              │
│   ─────────────────────────────────────────────────────────────────────    │
│   ai-shared-01 (4vCPU/16GB) : 학습+추론 통합 (CPU)                         │
│   ai-registry-01 (2vCPU/4GB): 모델 레지스트리                              │
│   ai-storage-01 (2vCPU/8GB) : 데이터 저장소                                │
│                                                                             │
│   계층 4: 서비스 계층 (2대)                                                 │
│   ─────────────────────────────────────────────────────────────────────    │
│   ai-gateway-01 (2vCPU/4GB) : API Gateway                                  │
│   ai-router-01 (2vCPU/4GB)  : 추론 라우터                                  │
│                                                                             │
│   ═══════════════════════════════════════════════════════════════════════  │
│   총계: ~24vCPU / ~76GB Memory / GPU 0개                                   │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 10.3 리소스 요약

| 구성 | vCPU | Memory | GPU | 스토리지 | VM 수 |
|------|------|--------|-----|---------|-------|
| **엔터프라이즈** | ~52 | ~300GB | 6~8 | 5TB | ~18대 |
| **데모 (GPU 있음)** | ~30 | ~150GB | 2~4 | 2TB | ~12대 |
| **데모 (GPU 없음)** | ~24 | ~76GB | 0 | 1TB | ~12대 |

---

## 11. 검증 시나리오

### 11.1 AI 플랫폼 검증 시나리오

| 시나리오 ID | 검증 항목 | 절차 | 예상 결과 |
|------------|----------|------|----------|
| **AI-01** | 테넌트 데이터 격리 | 테넌트 A에서 테넌트 B 데이터 접근 시도 | 접근 거부 |
| **AI-02** | 품질 게이트 동작 | 품질 미달 데이터 제출 | 게이트에서 반려 |
| **AI-03** | 공용 모델 학습 | 승인된 데이터로 학습 작업 실행 | 모델 생성 및 레지스트리 등록 |
| **AI-04** | 추론 라우팅 | 테넌트 A 요청 | 테넌트 A 모델 우선, 없으면 공용 모델 |
| **AI-05** | GPU 쿼터 | 쿼터 초과 학습 요청 | 큐 대기 또는 거부 |
| **AI-06** | 모델 폴백 | 테넌트 모델 서버 장애 | 공용 모델로 자동 전환 |

### 11.2 GPU 검증 시나리오 (GPU 있는 경우)

| 시나리오 ID | 검증 항목 | 절차 | 예상 결과 |
|------------|----------|------|----------|
| **GPU-01** | vGPU 할당 | 테넌트 VM에 vGPU 할당 | nvidia-smi로 확인 |
| **GPU-02** | 메모리 격리 | 할당량 초과 메모리 사용 시도 | OOM 에러 (다른 테넌트 영향 없음) |
| **GPU-03** | 분산 학습 | 2 GPU로 분산 학습 실행 | GPU 간 통신 정상 |
| **GPU-04** | 스케줄링 | 동시 다수 작업 요청 | 우선순위에 따라 스케줄링 |

---

## 관련 문서

- [01_프로젝트_개요서.md](01_프로젝트_개요서.md) - AI 플랫폼 4계층 구조 정의
- [04_컴퓨트_설계서.md](04_컴퓨트_설계서.md) - VM 배치, HA 설계
- [05_네트워크_보안_설계서.md](05_네트워크_보안_설계서.md) - 네트워크 격리
- [06_스토리지_설계서.md](06_스토리지_설계서.md) - Ceph 스토리지 설계

---

## 변경 이력

| 버전 | 날짜 | 변경 내용 | 작성자 |
|------|------|----------|--------|
| 1.0 | 2026-02-02 | 초안 작성 | - |
