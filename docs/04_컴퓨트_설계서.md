# 컴퓨트 설계서

## 공공기관 AI 공동 활용 인프라 구축 프로젝트
### AI 기반 문서 태깅 시스템을 위한 멀티 테넌트 프라이빗 클라우드 설계

| 항목 | 내용 |
|------|------|
| 문서명 | 컴퓨트 설계서 |
| 버전 | 4.0 |
| 작성일 | 2026-02-05 |
| 담당팀 | 컴퓨트/개발 팀 |

---

**목차**

1. [설계 개요 및 목표](#1-설계-개요-및-목표)
2. [리소스 풀 설계](#2-리소스-풀-설계)
3. [VM 배치 전략](#3-vm-배치-전략)
4. [리소스 쿼터](#4-리소스-쿼터)
5. [고가용성(HA) 설계](#5-고가용성ha-설계)
6. [GPU 가상화 설계](#6-gpu-가상화-설계)
7. [GPU 스케줄링 및 할당 정책](#7-gpu-스케줄링-및-할당-정책)
8. [VM 템플릿 및 표준화](#8-vm-템플릿-및-표준화)
9. [검증 워크로드 배포 계획](#9-검증-워크로드-배포-계획)

---

## 1. 설계 개요 및 목표

### 1.1 설계 목표

| 목표 | 설명 | 검증 방법 |
|------|------|----------|
| **문서 태깅 플랫폼** | 문서 자동 태깅 서비스를 위한 컴퓨트 인프라 | 태깅 서비스 정상 동작 |
| **테넌트 격리** | 테넌트별 문서 접근 권한 분리 | 테넌트 간 문서 접근 차단 확인 |
| **고가용성** | 서비스 VM 장애 시 자동 복구 | Failover 테스트 |
| **GPU 설계** | 향후 확장을 위한 GPU 가상화 설계 (설계만) | 설계 문서 검토 |
| **표준화** | VM 템플릿으로 일관된 환경 | 템플릿 기반 배포 |

### 1.2 설계 범위 정의

> **핵심 원칙**: 본 프로젝트는 AI 기반 문서 태깅 플랫폼 인프라 구축 프로젝트이다.
> 테넌트(부서)는 문서 업로드 및 검색 기능을 사용하며, AI 자동 태깅 서비스는 공용 플랫폼에서 제공한다.

**범위에 포함:**
- 문서 태깅 플랫폼 (웹 서버, API Gateway, 태깅 워커, 모델 서빙)
- 메타데이터 DB, 검색 서버
- 관리/운영 VM (모니터링)
- GPU 가상화 설계 (설계 문서만, 구현은 사전 학습 모델 업로드)

**범위에 제외:**
- 대규모 GPU 기반 학습 (설계만 포함, 구현은 로컬 학습 후 모델 업로드)
- OCR 기능 (설계만 포함, 구현은 추후 확장)

### 1.3 상세 설계 범위

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                   문서 태깅 플랫폼 컴퓨트 설계 범위                            │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   In-Scope (담당 영역)                                                      │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  - 리소스 풀 구성 및 관리                                            │  │
│   │  - VM 배치 전략 (Affinity/Anti-Affinity)                            │  │
│   │  - 장애 도메인 설계 (서비스 HA)                                      │  │
│   │  - HA 설정 (VM 자동 재시작, Live Migration)                         │  │
│   │  - GPU 가상화 설계 (vGPU, MIG, Passthrough) - 설계 문서만            │  │
│   │  - VM 템플릿 관리 (웹서버/API/태깅워커/모델서빙/DB)                  │  │
│   │  - 검증 워크로드 배포 (문서 자동 태깅 서비스)                        │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   Out-of-Scope (범위 제외)                                                  │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  ✗ 대규모 GPU 기반 학습 구현 (설계만)                                │  │
│   │  ✗ OCR 기능 구현 (설계만)                                            │  │
│   │  → 구현: 로컬에서 사전 학습된 모델 업로드                            │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   협업 영역 (다른 팀과 공동)                                                │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  - VM 네트워크 연결 (네트워크 팀)                                    │  │
│   │  - VM 스토리지 연결 (스토리지 팀)                                    │  │
│   │  - 메트릭 수집 (공통)                                                │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 2. 리소스 풀 설계

### 2.1 풀 구성 전략

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        리소스 풀 구조                                        │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│                         ┌─────────────────┐                                │
│                         │   Root Pool     │                                │
│                         │  (전체 클러스터) │                                │
│                         └────────┬────────┘                                │
│                                  │                                          │
│     ┌────────────────────────────┼────────────────────────────┐            │
│     │                            │                            │            │
│     ▼                            ▼                            ▼            │
│   ┌─────────────┐         ┌─────────────┐         ┌─────────────┐         │
│   │ 서비스 풀   │         │ 데이터 풀   │         │ 관리 풀     │         │
│   │ (태깅 서비스)│         │ (DB/검색)   │         │ (운영)      │         │
│   └──────┬──────┘         └──────┬──────┘         └─────────────┘         │
│          │                       │                                         │
│   ┌──────┼──────┐         ┌──────┼──────┐                                 │
│   │      │      │         │      │      │                                 │
│   ▼      ▼      ▼         ▼      ▼      ▼                                 │
│ ┌─────┐┌─────┐┌─────┐  ┌─────┐┌─────┐┌─────┐                             │
│ │웹   ││API  ││태깅 │  │메타 ││검색 ││모델 │                             │
│ │서버 ││GW   ││워커 │  │DB   ││서버 ││서빙 │                             │
│ └─────┘└─────┘└─────┘  └─────┘└─────┘└─────┘                             │
│                                                                             │
│   서비스 풀: 웹 서버, API Gateway, 태깅 워커                               │
│   데이터 풀: 메타데이터 DB, 검색 서버, 모델 서빙                           │
│   관리 풀: 모니터링, 로깅                                                  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 2.2 오버커밋 정책

| 리소스 | 오버커밋 비율 | 설명 |
|--------|-------------|------|
| **CPU** | 2:1 | 물리 1코어당 가상 2코어 할당 가능 |
| **Memory** | 1:1 | 메모리는 오버커밋 없음 (안정성) |
| **GPU** | 오버커밋 없음 | GPU 메모리는 정확한 할당 필요 (설계) |
| **Storage** | Thin Provisioning | 실제 사용량만 할당 |

**오버커밋 설정 근거:**
- CPU는 일반적으로 100% 사용되지 않으므로 2:1 오버커밋 적용
- Memory는 스왑 발생 시 성능 저하가 심하므로 오버커밋 없음
- GPU는 VRAM 부족 시 OOM 발생하므로 오버커밋 불가 (설계 시 고려)
- 스토리지는 Thin Provisioning으로 효율적 활용

### 2.3 클러스터 구성

| 구성 요소 | 수량 | 설명 |
|----------|------|------|
| **Zone** | 1개 | 단일 데이터센터 |
| **Pod** | 1개 | 네트워크 도메인 |
| **Cluster** | 1개 | 호스트 그룹 |
| **Host** | 가용 호스트 | HCI 노드 |
| **GPU Host** | 1개 (설계) | GPU 장착 노드 (설계만) |

---

## 3. VM 배치 전략

### 3.1 Affinity / Anti-Affinity

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                     Affinity / Anti-Affinity 규칙                           │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   Anti-Affinity (분산 배치) - HA 목적                                       │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │                                                                     │  │
│   │   Host 1              Host 2              Host 3                    │  │
│   │   ┌─────────┐        ┌─────────┐        ┌─────────┐                │  │
│   │   │ Web-01  │        │ Web-02  │        │ API-01  │                │  │
│   │   │ (웹서버)│        │ (웹서버)│        │ (API GW)│                │  │
│   │   └─────────┘        └─────────┘        └─────────┘                │  │
│   │                                                                     │  │
│   │   ✓ 동일 서비스 VM은 다른 호스트에 분산 → 호스트 장애 시 서비스 유지 │  │
│   │                                                                     │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   Affinity (동일 배치) - 성능 목적                                          │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │                                                                     │  │
│   │   Host 1                                                            │  │
│   │   ┌─────────┐  ┌─────────┐  ┌─────────┐                            │  │
│   │   │Tagging │──│Model   │──│  DB     │  ← 태깅 워커-모델 서빙-DB는  │  │
│   │   │Worker  │  │Serving │  │         │    동일 호스트 (레이턴시)    │  │
│   │   └─────────┘  └─────────┘  └─────────┘                            │  │
│   │                                                                     │  │
│   │   ✓ 빈번하게 통신하는 VM은 동일 호스트에 배치                       │  │
│   │                                                                     │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 3.2 배치 규칙 정의

| 규칙 ID | 유형 | 대상 VM | 설명 |
|---------|------|--------|------|
| **AA-001** | Anti-Affinity | 웹 서버 | 서비스 HA를 위해 분산 배치 |
| **AA-002** | Anti-Affinity | API Gateway | 서비스 HA |
| **AA-003** | Anti-Affinity | 태깅 워커 | 처리 분산 |
| **AF-001** | Affinity | 태깅워커-모델서빙 | 레이턴시 최소화 |
| **AF-002** | Affinity | 검색서버-메타DB | 빠른 쿼리 응답 |

### 3.3 장애 도메인 분리

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        장애 도메인 설계                                      │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   장애 도메인 레벨:                                                         │
│                                                                             │
│   Level 1: Host (호스트)                                                    │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  단일 호스트 장애 시 해당 호스트의 VM만 영향                         │  │
│   │  → Anti-Affinity로 중요 VM 분산 배치                                 │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   Level 2: Rack (랙) - 설계 문서용                                         │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  랙 단위 장애 (전원, 네트워크) 시 해당 랙의 모든 호스트 영향         │  │
│   │  → 중요 서비스는 다른 랙에 분산 (실제 구현 시)                       │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   데모 환경 적용:                                                           │
│   - Host 레벨 Anti-Affinity 적용                                           │
│   - 호스트 장애 시 VM 자동 재시작 (다른 호스트에서)                         │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 4. 리소스 쿼터

### 4.1 쿼터 정책

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        리소스 쿼터 설계                                      │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   문서 태깅 플랫폼 환경 할당:                                               │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │                                                                     │  │
│   │   [서비스 계층]                                                     │  │
│   │   웹 서버: vCPU 2개, Memory 4GB, VM 2대                            │  │
│   │   API Gateway: vCPU 2개, Memory 4GB, VM 2대                        │  │
│   │   태깅 워커: vCPU 4개, Memory 8GB, VM 2대                          │  │
│   │   모델 서빙: vCPU 4개, Memory 8GB, VM 2대 (사전학습 모델)          │  │
│   │                                                                     │  │
│   │   [데이터 계층]                                                     │  │
│   │   메타데이터 DB: vCPU 4개, Memory 8GB, VM 1대                      │  │
│   │   검색 서버: vCPU 4개, Memory 8GB, VM 1대                          │  │
│   │                                                                     │  │
│   │   [관리/운영]                                                       │  │
│   │   모니터링: vCPU 2개, Memory 4GB, VM 1대                           │  │
│   │   ─────────────────────────────────────────────────────────────    │  │
│   │   합계: vCPU ~30개, Memory ~60GB, VM ~11대                        │  │
│   │                                                                     │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 4.2 VM 리소스 할당

| 구성 요소 | vCPU | Memory | VM 수 | 디스크 | 용도 |
|----------|------|--------|-------|--------|------|
| **웹 서버** | 2개 | 4 GB | 2대 | 50 GB | 문서 업로드/검색 UI |
| **API Gateway** | 2개 | 4 GB | 2대 | 50 GB | 인증 연동, 라우팅 |
| **태깅 워커** | 4개 | 8 GB | 2대 | 100 GB | 비동기 문서 태깅 |
| **모델 서빙** | 4개 | 8 GB | 2대 | 100 GB | 사전학습 모델 추론 |
| **메타데이터 DB** | 4개 | 8 GB | 1대 | 200 GB | 문서 메타데이터, 태그 |
| **검색 서버** | 4개 | 8 GB | 1대 | 100 GB | 태그 기반 검색 |
| **모니터링** | 2개 | 4 GB | 1대 | 80 GB | Prometheus/Grafana |

### 4.3 테넌트별 사용량 관리

> 테넌트(부서)는 VM을 직접 소유하지 않고, 공용 플랫폼을 사용한다.
> 사용량은 문서 업로드 용량과 검색 횟수로 관리된다.

| 테넌트 | 문서 저장 용량 | 월간 검색 횟수 | 비고 |
|--------|---------------|---------------|------|
| **부서 A** | 100 GB | 무제한 | 테넌트 관리자 1명 |
| **부서 B** | 100 GB | 무제한 | 테넌트 관리자 1명 |
| **부서 C** | 100 GB | 무제한 | 테넌트 관리자 1명 |

### 4.4 쿼터 초과 정책

| 상황 | 정책 |
|------|------|
| 문서 저장 용량 80% 도달 | 테넌트 관리자 경고 알림 |
| 문서 저장 용량 100% 도달 | 추가 업로드 차단 |
| 동시 태깅 요청 과다 | 큐 대기 (비동기 처리) |

---

## 5. 고가용성(HA) 설계

### 5.1 HA 전략

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        고가용성 설계                                         │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   장애 시나리오:                                                            │
│                                                                             │
│   [정상 상태]                      [장애 발생]                              │
│   ┌─────────┐  ┌─────────┐        ┌─────────┐  ┌─────────┐               │
│   │ Host 1  │  │ Host 2  │        │ Host 1  │  │ Host 2  │               │
│   │ ┌─────┐ │  │ ┌─────┐ │        │   ✗     │  │ ┌─────┐ │               │
│   │ │VM-A │ │  │ │VM-B │ │   ──►  │ 장애!   │  │ │VM-B │ │               │
│   │ └─────┘ │  │ └─────┘ │        │         │  │ │VM-A │ │ ← 자동 이전   │
│   └─────────┘  └─────────┘        └─────────┘  │ └─────┘ │               │
│                                                └─────────┘               │
│                                                                             │
│   HA 동작 순서:                                                             │
│   1. 호스트 장애 감지 (하트비트 타임아웃)                                   │
│   2. 해당 호스트의 VM 목록 확인                                             │
│   3. 다른 호스트에서 VM 재시작                                              │
│   4. 네트워크/스토리지 재연결                                               │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 5.2 HA 설정

| 설정 항목 | 값 | 설명 |
|----------|-----|------|
| **HA 활성화** | 예 | 클러스터 레벨 HA 활성화 |
| **장애 감지 시간** | 30초 | 하트비트 타임아웃 |
| **자동 재시작** | 예 | 장애 VM 자동 재시작 |
| **재시작 우선순위** | High/Medium/Low | VM별 우선순위 설정 |

### 5.3 Live Migration

| 항목 | 설명 |
|------|------|
| **목적** | 서비스 중단 없이 VM을 다른 호스트로 이동 |
| **사용 시점** | 호스트 유지보수, 부하 분산 |
| **요구 사항** | 공유 스토리지 (Ceph), 동일 CPU 아키텍처 |

```
Live Migration 프로세스:

   Host 1                              Host 2
   ┌─────────┐                        ┌─────────┐
   │ [VM-A]  │  ──── 메모리 복사 ────► │ [VM-A'] │
   │ Running │                        │ 준비 중 │
   └─────────┘                        └─────────┘
        │                                  │
        │         ◄── 최종 동기화 ──►       │
        │                                  │
   ┌─────────┐                        ┌─────────┐
   │   ---   │                        │ [VM-A]  │
   │ 종료됨  │                        │ Running │
   └─────────┘                        └─────────┘

   - 다운타임: 수 초 이내
   - 스토리지: Ceph RBD (공유)
```

---

## 6. GPU 가상화 설계

> **참고**: GPU 가상화는 본 프로젝트에서 **설계 문서**에만 포함됩니다.
> 실제 구현 단계에서는 로컬에서 사전 학습된 모델을 업로드하여 CPU 기반 추론 또는 단일 GPU 추론으로 검증합니다.

### 6.1 GPU 가상화 전략 (설계)

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        GPU 가상화 전략 (설계 문서용)                          │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   본 프로젝트는 다음 GPU 가상화 방식을 설계 문서에서 비교 분석한다:         │
│                                                                             │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  1. 학습용: GPU Passthrough (설계)                                  │  │
│   │  ─────────────────────────────────────────────────────────────────  │  │
│   │  • 대규모 모델 학습에 100% 성능 필요                                │  │
│   │  • 단일 VM에 전체 GPU 할당                                          │  │
│   │  • Live Migration 불가                                              │  │
│   │  ※ 설계 문서에만 포함, 구현은 로컬 학습 후 모델 업로드             │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  2. 추론용: vGPU (NVIDIA GRID) (설계)                               │  │
│   │  ─────────────────────────────────────────────────────────────────  │  │
│   │  • 다수 VM에 GPU 공유                                               │  │
│   │  • 프로파일 기반 메모리 분할 (4GB, 8GB, 16GB 등)                    │  │
│   │  • Live Migration 지원                                              │  │
│   │  ※ 설계 문서에만 포함, 구현은 CPU 추론 또는 단일 GPU              │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   구현 단계 검증 방법:                                                     │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  • 로컬에서 사전 학습된 텍스트 분류 모델 (.pt, .onnx) 업로드         │  │
│   │  • CPU 기반 추론으로 태깅 서비스 검증                                │  │
│   │  • 또는 단일 GPU로 추론 성능 검증                                    │  │
│   │  • 대규모 분산 학습은 설계 문서로 대체                               │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 6.2 vGPU 프로파일 설계 (설계 문서용)

| 프로파일 ID | VRAM | 용도 | 최대 VM 수 (24GB GPU) |
|-------------|------|------|---------------------|
| **PROF-4Q** | 4 GB | 경량 추론, 개발 | 6개 |
| **PROF-8Q** | 8 GB | 일반 추론 | 3개 |
| **PROF-12Q** | 12 GB | 대형 모델 추론 | 2개 |
| **PROF-16Q** | 16 GB | 파인튜닝 | 1개 |
| **PROF-24Q** | 24 GB | 전체 GPU | 1개 |

### 6.3 GPU 호스트 구성 (설계 문서용)

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        GPU 호스트 구성 (설계)                                │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   GPU Host (추론용 - 설계)                                                  │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  GPU #0: vGPU (GRID)                                                │  │
│   │          ├── 모델 서빙 VM 1: PROF-8Q (8GB)                          │  │
│   │          ├── 모델 서빙 VM 2: PROF-8Q (8GB)                          │  │
│   │          └── 공용 (대기): PROF-8Q (8GB)                             │  │
│   │                                                                     │  │
│   │  ※ 설계 문서용: 실제 구현은 CPU 추론 또는 단일 GPU 사용            │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 6.4 GPU 드라이버 및 소프트웨어 스택 (설계)

| 계층 | 컴포넌트 | 버전 (예시) |
|------|---------|-----------|
| **Host** | NVIDIA Driver | 535.x |
| **Host** | NVIDIA GRID vGPU Manager | 16.x |
| **Guest** | NVIDIA vGPU Guest Driver | 535.x |
| **Guest** | CUDA Toolkit | 12.x |
| **Guest** | cuDNN | 8.x |
| **Guest** | PyTorch/TensorFlow | 최신 |

---

## 7. GPU 스케줄링 및 할당 정책

> **참고**: 이 섹션은 설계 문서용입니다. 실제 구현에서는 CPU 추론을 사용합니다.

### 7.1 GPU 스케줄링 아키텍처 (설계)

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        GPU 스케줄링 아키텍처 (설계)                          │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │                     작업 요청 큐 (Job Queue)                        │  │
│   │                                                                     │  │
│   │   [실시간 추론]  [배치 추론]  [모델 업데이트]                       │  │
│   │   Priority:1     Priority:2   Priority:3                            │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                    │                                        │
│                                    ▼                                        │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │                        GPU 스케줄러 (설계)                          │  │
│   │  ─────────────────────────────────────────────────────────────────  │  │
│   │                                                                     │  │
│   │  1. Fair-Share 계산                                                 │  │
│   │     → 테넌트별 공정한 GPU 시간 배분                                │  │
│   │                                                                     │  │
│   │  2. 우선순위 적용                                                   │  │
│   │     → 실시간 추론 > 배치 추론 > 모델 업데이트                      │  │
│   │                                                                     │  │
│   │  3. vGPU 풀 선택                                                    │  │
│   │     → 프로파일 기반 할당                                           │  │
│   │                                                                     │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   ※ 실제 구현: 비동기 큐 기반 처리 (RabbitMQ + Celery)                    │
│      GPU 없이 CPU 추론으로 대체 가능                                       │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 7.2 할당 정책 (설계)

| 정책 항목 | 설정 | 설명 |
|----------|------|------|
| **우선순위** | 3단계 | 실시간(1) → 배치(2) → 업데이트(3) |
| **최대 작업 시간** | 추론 30초 | 단일 추론 요청 타임아웃 |
| **대기열** | Priority FIFO | 우선순위 내 FIFO |

### 7.3 모니터링 메트릭

| 메트릭 | 수집 주기 | 임계치 | 알림 |
|--------|----------|--------|------|
| **CPU Utilization** | 10초 | 90% 이상 5분 지속 | Warning |
| **Memory Usage** | 10초 | 95% 이상 | Critical |
| **태깅 큐 길이** | 10초 | 100개 이상 | Warning |
| **태깅 처리 지연** | 10초 | 60초 이상 | Warning |

---

## 8. VM 템플릿 및 표준화

### 8.1 VM 템플릿 목록

| 템플릿 ID | OS | 스펙 | 용도 | 포함 패키지 |
|----------|-----|------|------|------------|
| **TPL-WEB** | Ubuntu 22.04 | 2vCPU/4GB | 웹 서버 | nginx, python, gunicorn |
| **TPL-API-GW** | Ubuntu 22.04 | 2vCPU/4GB | API Gateway | nginx, kong |
| **TPL-TAGGING** | Ubuntu 22.04 | 4vCPU/8GB | 태깅 워커 | python, celery, rabbitmq |
| **TPL-MODEL** | Ubuntu 22.04 | 4vCPU/8GB | 모델 서빙 | python, fastapi, pytorch |
| **TPL-DB** | Ubuntu 22.04 | 4vCPU/8GB | 메타데이터 DB | postgresql |
| **TPL-SEARCH** | Ubuntu 22.04 | 4vCPU/8GB | 검색 서버 | elasticsearch |
| **TPL-MON** | Ubuntu 22.04 | 2vCPU/4GB | 모니터링 | prometheus, grafana |

### 8.2 서비스 VM 템플릿 구성 상세

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        VM 템플릿 구성                                        │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   TPL-TAGGING (태깅 워커):                                                  │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  - Ubuntu 22.04 LTS                                                 │  │
│   │  - Python 3.10+                                                     │  │
│   │  - Celery (비동기 작업 큐)                                          │  │
│   │  - RabbitMQ Client                                                  │  │
│   │  - 텍스트 처리 라이브러리                                           │  │
│   │  - node_exporter (메트릭)                                           │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   TPL-MODEL (모델 서빙):                                                    │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  - Ubuntu 22.04 LTS                                                 │  │
│   │  - Python 3.10+                                                     │  │
│   │  - PyTorch 2.x (CPU 버전)                                          │  │
│   │  - FastAPI (추론 API)                                               │  │
│   │  - 사전 학습 모델 로드 스크립트                                     │  │
│   │  - node_exporter (메트릭)                                           │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   Cloud-init 설정:                                                          │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  #cloud-config                                                      │  │
│   │  hostname: ${vm_name}                                               │  │
│   │  timezone: Asia/Seoul                                               │  │
│   │  runcmd:                                                            │  │
│   │    - systemctl enable tagging-worker                                │  │
│   │    - systemctl start tagging-worker                                 │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 8.3 VM 명명 규칙

```
{환경}-{용도}-{역할}-{번호}

예시:
- dev-svc-web-01      : 개발환경, 서비스, 웹서버, 1번
- dev-svc-api-01      : 개발환경, 서비스, API Gateway, 1번
- dev-svc-tagging-01  : 개발환경, 서비스, 태깅워커, 1번
- dev-data-model-01   : 개발환경, 데이터, 모델서빙, 1번
- dev-data-db-01      : 개발환경, 데이터, DB, 1번
- dev-data-search-01  : 개발환경, 데이터, 검색서버, 1번
- dev-mgmt-mon-01     : 개발환경, 관리, 모니터링, 1번
```

---

## 9. 검증 워크로드 배포 계획

### 9.1 검증 목적

> 인프라 설계의 정상 동작을 확인하기 위한 샘플 워크로드 배포

| 검증 항목 | 검증 방법 |
|----------|----------|
| **테넌트 격리** | 테넌트 간 문서 접근 불가 확인 |
| **HA** | 호스트 장애 시 VM 자동 재시작 확인 |
| **Anti-Affinity** | VM이 다른 호스트에 분산되었는지 확인 |
| **비동기 처리** | 문서 업로드 → 태깅 완료 흐름 확인 |
| **검색 기능** | 태그 기반 문서 검색 동작 확인 |

### 9.2 검증 환경 VM 구성

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                   문서 태깅 플랫폼 검증 워크로드 배포 구성                     │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   [서비스 계층]                                                              │
│   ┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐              │
│   │ dev-svc-web-01  │ │ dev-svc-web-02  │ │ dev-svc-api-01  │              │
│   │ (2vCPU/4GB)     │ │ (2vCPU/4GB)     │ │ (2vCPU/4GB)     │              │
│   │ 웹 서버 #1      │ │ 웹 서버 #2      │ │ API Gateway     │              │
│   └─────────────────┘ └─────────────────┘ └─────────────────┘              │
│                                                                             │
│   [비즈니스 계층]                                                            │
│   ┌─────────────────┐ ┌─────────────────┐                                  │
│   │dev-svc-tagging-01│ │dev-svc-tagging-02│                                  │
│   │ (4vCPU/8GB)     │ │ (4vCPU/8GB)     │                                  │
│   │ 태깅 워커 #1    │ │ 태깅 워커 #2    │                                  │
│   └─────────────────┘ └─────────────────┘                                  │
│                                                                             │
│   [데이터 계층]                                                              │
│   ┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐              │
│   │dev-data-model-01│ │ dev-data-db-01  │ │dev-data-search-01│              │
│   │ (4vCPU/8GB)     │ │ (4vCPU/8GB)     │ │ (4vCPU/8GB)     │              │
│   │ 모델 서빙       │ │ PostgreSQL      │ │ Elasticsearch   │              │
│   │ (사전학습모델)  │ │ 메타데이터 DB   │ │ 검색 엔진       │              │
│   └─────────────────┘ └─────────────────┘ └─────────────────┘              │
│                                                                             │
│   [관리 계층]                                                                │
│   ┌─────────────────┐                                                       │
│   │ dev-mgmt-mon-01 │                                                       │
│   │ (2vCPU/4GB)     │                                                       │
│   │ Prometheus      │                                                       │
│   │ Grafana         │                                                       │
│   └─────────────────┘                                                       │
│                                                                             │
│   총 VM: 10대                                                               │
│   ※ 사전 학습 모델 업로드로 AI 태깅 검증                                   │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 9.3 검증 시나리오

| 시나리오 | 절차 | 예상 결과 |
|----------|------|----------|
| **SC-01: 테넌트 격리** | 부서 A에서 부서 B 문서 조회 시도 | 접근 거부 |
| **SC-02: HA 테스트** | 호스트 장애 시뮬레이션 | VM 자동 재시작 |
| **SC-03: Anti-Affinity** | 동일 서비스 VM 배치 확인 | 다른 호스트에 분산 |
| **SC-04: 문서 업로드** | 문서 업로드 후 태깅 확인 | 자동 태깅 완료 |
| **SC-05: 문서 검색** | 태그 기반 검색 | 정상 결과 반환 |
| **SC-06: 비동기 처리** | 대량 문서 업로드 | 큐잉 후 순차 처리 |

### 9.4 검증 워크로드: 문서 자동 태깅

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                   문서 자동 태깅 워크로드 (검증용)                            │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   목표 서비스: 문서 자동 태깅                                               │
│   - 기능: 문서 업로드 시 내용 기반 자동 태깅                                │
│   - 기술: 텍스트 분류 모델 (사전 학습)                                      │
│   - 구현 수준: 인프라 검증용 샘플 워크로드                                  │
│                                                                             │
│   1. 모델 준비                                                              │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  - 모델: 사전 학습된 텍스트 분류 모델 (.pt, .onnx)                   │  │
│   │  - 분류 카테고리: 5~10개 태그                                       │  │
│   │  - 로컬에서 학습 후 플랫폼에 업로드                                  │  │
│   │  - CPU 추론으로 검증                                                 │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   2. 태깅 워크플로우                                                        │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  [사용자] 문서 업로드                                               │  │
│   │      ↓                                                              │  │
│   │  [웹 서버] 문서 저장, 태깅 요청 큐에 등록                           │  │
│   │      ↓                                                              │  │
│   │  [태깅 워커] 큐에서 작업 수신                                       │  │
│   │      ↓                                                              │  │
│   │  [모델 서빙] 텍스트 분류 추론                                       │  │
│   │      ↓                                                              │  │
│   │  [메타데이터 DB] 태그 저장                                          │  │
│   │      ↓                                                              │  │
│   │  [사용자] 태그 기반 검색 가능                                       │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   3. 추론 API                                                               │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  - REST API: POST /api/v1/predict                                   │  │
│   │  - 입력: 문서 텍스트                                                │  │
│   │  - 출력: 태그 목록, 신뢰도 점수                                     │  │
│   │  - 지연 시간 목표: <500ms (CPU 추론)                                │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 변경 이력

| 버전 | 날짜 | 변경 내용 | 작성자 |
|------|------|----------|--------|
| 1.0 | 2026-01-30 | 초안 작성 | - |
| 2.0 | 2026-02-02 | **GPU 가상화 통합**: GPU 설계, vGPU 프로파일, GPU 스케줄링 추가 | - |
| 3.0 | 2026-02-04 | **AI 플랫폼 중심 재구성**: 민원 자동 분류 워크로드 | - |
| 4.0 | 2026-02-05 | **문서 태깅 시스템**: 서비스 변경, 테넌트 익명화(부서 A/B/C), GPU 설계만 포함, 사전학습 모델 업로드 방식 | - |

---

## 관련 문서

- [00_프로젝트_계획서.md](00_프로젝트_계획서.md)
- [01_요구사항_명세서.md](01_요구사항_명세서.md)
- [01_프로젝트_개요서.md](01_프로젝트_개요서.md)
- [02_팀_역할분담.md](02_팀_역할분담.md)
- [03_상세설계_가이드.md](03_상세설계_가이드.md)
- [05_네트워크_보안_설계서.md](05_네트워크_보안_설계서.md)
- [06_스토리지_설계서.md](06_스토리지_설계서.md)
