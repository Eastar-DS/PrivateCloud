# 컴퓨트 설계서

## 지자체 공동활용 AI 플랫폼 인프라 구축 프로젝트
### 공공 데이터 주권 확보를 위한 멀티테넌트 프라이빗 클라우드 설계

| 항목 | 내용 |
|------|------|
| 문서명 | 컴퓨트 설계서 |
| 버전 | 3.0 |
| 작성일 | 2026-02-02 |
| 담당팀 | 컴퓨트/개발 팀 |

---

**목차**

1. [설계 개요 및 목표](#1-설계-개요-및-목표)
2. [리소스 풀 설계](#2-리소스-풀-설계)
3. [VM 배치 전략](#3-vm-배치-전략)
4. [리소스 쿼터](#4-리소스-쿼터)
5. [고가용성(HA) 설계](#5-고가용성ha-설계)
6. [GPU 가상화 설계](#6-gpu-가상화-설계)
7. [GPU 스케줄링 및 할당 정책](#7-gpu-스케줄링-및-할당-정책)
8. [VM 템플릿 및 표준화](#8-vm-템플릿-및-표준화)
9. [검증 워크로드 배포 계획](#9-검증-워크로드-배포-계획)

---

## 1. 설계 개요 및 목표

### 1.1 설계 목표

| 목표 | 설명 | 검증 방법 |
|------|------|----------|
| **AI 플랫폼 컴퓨트** | AI 학습/추론 서비스를 위한 컴퓨트 인프라 | GPU VM 정상 동작 |
| **테넌트 API 격리** | 테넌트별 AI 서비스 접근 쿼터 관리 | API 사용량 제한 확인 |
| **고가용성** | AI 서비스 VM 장애 시 자동 복구 | Failover 테스트 |
| **GPU 공유** | 멀티테넌트 GPU 자원 공유 (공용 GPU 풀) | vGPU 할당 확인 |
| **표준화** | AI VM 템플릿으로 일관된 환경 | 템플릿 기반 배포 |

### 1.2 설계 범위 정의

> **핵심 원칙**: 본 프로젝트는 AI 플랫폼 인프라 구축 프로젝트이다.
> 테넌트는 업무 시스템(웹/앱/DB)을 운영하지 않으며, AI 서비스 이용자(데이터 제공자)로서 참여한다.

**범위에 포함:**
- 공용 AI 플랫폼 (학습/추론 서버)
- 품질 게이트 VM
- 관리/운영 VM
- 테넌트 데이터 업로드용 최소 VM (선택)

**범위에 제외:**
- 테넌트 웹서버, 앱서버, DB서버 (업무 시스템 마이그레이션 아님)
- 테넌트별 전용 GPU (공용 GPU 풀 사용)

### 1.3 상세 설계 범위

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                   AI 플랫폼 컴퓨트 설계 범위                                  │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   In-Scope (담당 영역)                                                      │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  - AI 전용 리소스 풀 구성 및 관리                                    │  │
│   │  - GPU VM 배치 전략 (Affinity/Anti-Affinity)                        │  │
│   │  - 장애 도메인 설계 (AI 서비스 HA)                                   │  │
│   │  - 테넌트 API 사용량 쿼터 정책                                       │  │
│   │  - 공용 GPU 풀 쿼터 정책                                             │  │
│   │  - HA 설정 (AI 서비스 VM 자동 재시작, Live Migration)               │  │
│   │  - GPU 가상화 설계 (vGPU, MIG, Passthrough)                         │  │
│   │  - GPU 스케줄링 및 할당 정책                                         │  │
│   │  - AI VM 템플릿 관리 (학습/추론/품질게이트/데이터업로드)            │  │
│   │  - 검증 워크로드 배포 (민원 자동 분류 AI)                            │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   Out-of-Scope (범위 제외)                                                  │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  ✗ 테넌트 웹서버 VM                                                  │  │
│   │  ✗ 테넌트 앱서버 VM                                                  │  │
│   │  ✗ 테넌트 DB서버 VM                                                  │  │
│   │  ✗ 일반 업무 시스템 마이그레이션                                     │  │
│   │  → 본 프로젝트는 AI 플랫폼 인프라만 구축                             │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   협업 영역 (다른 팀과 공동)                                                │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  - GPU VM 네트워크 연결 (네트워크 팀)                                │  │
│   │  - GPU VM AI 스토리지 연결 (스토리지 팀)                             │  │
│   │  - GPU 메트릭 수집 (공통)                                            │  │
│   │  - 품질 게이트 연동 (네트워크 팀)                                    │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 2. 리소스 풀 설계

### 2.1 풀 구성 전략

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        리소스 풀 구조                                        │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│                         ┌─────────────────┐                                │
│                         │   Root Pool     │                                │
│                         │  (전체 클러스터) │                                │
│                         └────────┬────────┘                                │
│                                  │                                          │
│     ┌────────────────────────────┼────────────────────────────┐            │
│     │                            │                            │            │
│     ▼                            ▼                            ▼            │
│   ┌─────────────┐         ┌─────────────┐         ┌─────────────┐         │
│   │ 테넌트 데이터│         │ 공용 AI     │         │ 관리 풀     │         │
│   │ 영역 풀     │         │ 플랫폼 풀   │         │ (운영)      │         │
│   │ (선택적)    │         │ (GPU 포함)  │         │             │         │
│   └──────┬──────┘         └──────┬──────┘         └─────────────┘         │
│          │                       │                                         │
│          │                ┌──────┼──────┬──────────┐                       │
│          │                │      │      │          │                       │
│          ▼                ▼      ▼      ▼          ▼                       │
│   ┌─────────────┐  ┌─────────┐┌─────┐┌─────┐┌──────────┐                  │
│   │ 데이터     │  │ GPU    ││GPU ││품질 ││ DB/API  │                  │
│   │ 업로드 VM  │  │ 학습   ││추론 ││게이트││ Gateway │                  │
│   │ (테넌트별) │  │ 풀     ││풀   ││ VM  ││         │                  │
│   └─────────────┘  └─────────┘└─────┘└─────┘└──────────┘                  │
│                                                                             │
│   테넌트 데이터 영역: 데이터 업로드용 최소 VM (선택)                        │
│   GPU 학습 풀: 대규모 모델 학습용 (Passthrough)                            │
│   GPU 추론 풀: 추론 서비스용 (vGPU 공유)                                   │
│   품질 게이트 VM: 데이터 검증/익명화                                        │
│   관리 풀: DB, API Gateway, 모니터링                                        │
│   ※ 테넌트 웹/앱/DB 서버 없음                                              │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 2.2 오버커밋 정책

| 리소스 | 오버커밋 비율 | 설명 |
|--------|-------------|------|
| **CPU** | 2:1 | 물리 1코어당 가상 2코어 할당 가능 |
| **Memory** | 1:1 | 메모리는 오버커밋 없음 (안정성) |
| **GPU** | 오버커밋 없음 | GPU 메모리는 정확한 할당 필요 |
| **Storage** | Thin Provisioning | 실제 사용량만 할당 |

**오버커밋 설정 근거:**
- CPU는 일반적으로 100% 사용되지 않으므로 2:1 오버커밋 적용
- Memory는 스왑 발생 시 성능 저하가 심하므로 오버커밋 없음
- GPU는 VRAM 부족 시 OOM 발생하므로 오버커밋 불가
- 스토리지는 Thin Provisioning으로 효율적 활용

### 2.3 클러스터 구성

| 구성 요소 | 수량 | 설명 |
|----------|------|------|
| **Zone** | 1개 | 단일 데이터센터 |
| **Pod** | 1개 | 네트워크 도메인 |
| **Cluster** | 1개 | 호스트 그룹 |
| **Host** | 가용 호스트 | HCI 노드 |
| **GPU Host** | 1~2개 (설계) | GPU 장착 노드 |

---

## 3. VM 배치 전략

### 3.1 Affinity / Anti-Affinity

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                     Affinity / Anti-Affinity 규칙                           │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   Anti-Affinity (분산 배치) - HA 목적                                       │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │                                                                     │  │
│   │   Host 1              Host 2              Host 3 (GPU)             │  │
│   │   ┌─────────┐        ┌─────────┐        ┌─────────┐                │  │
│   │   │ Web-A1  │        │ Web-A2  │        │ AI-Inf  │                │  │
│   │   │ (테넌트A)│        │ (테넌트A)│        │ (추론)  │                │  │
│   │   └─────────┘        └─────────┘        └─────────┘                │  │
│   │                                                                     │  │
│   │   ✓ 동일 서비스 VM은 다른 호스트에 분산 → 호스트 장애 시 서비스 유지 │  │
│   │                                                                     │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   Affinity (동일 배치) - 성능/GPU 목적                                      │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │                                                                     │  │
│   │   GPU Host 1                                                        │  │
│   │   ┌─────────┐  ┌─────────┐  ┌─────────┐                            │  │
│   │   │Train-A │──│Train-B │──│Train-C │  ← 분산 학습 VM은 동일 GPU호스트│  │
│   │   │(GPU #0)│  │(GPU #1)│  │(GPU #2)│                               │  │
│   │   └─────────┘  └─────────┘  └─────────┘                            │  │
│   │                                                                     │  │
│   │   ✓ GPU 간 고속 통신 (NVLink/PCIe)                                  │  │
│   │                                                                     │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 3.2 배치 규칙 정의

| 규칙 ID | 유형 | 대상 VM | 설명 |
|---------|------|--------|------|
| **AA-001** | Anti-Affinity | 추론 서버 | AI 서비스 HA를 위해 분산 배치 |
| **AA-002** | Anti-Affinity | 품질 게이트 VM | 데이터 처리 HA |
| **AA-003** | Anti-Affinity | API Gateway | 서비스 HA |
| **AF-001** | Affinity | 분산 학습 VM | GPU 간 고속 통신 |
| **AF-002** | Affinity | 추론-캐시 쌍 | 레이턴시 최소화 |
| **GPU-001** | GPU Host Only | AI 학습/추론 VM | GPU 호스트에만 배치 |

### 3.3 장애 도메인 분리

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        장애 도메인 설계                                      │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   장애 도메인 레벨:                                                         │
│                                                                             │
│   Level 1: Host (호스트)                                                    │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  단일 호스트 장애 시 해당 호스트의 VM만 영향                         │  │
│   │  → Anti-Affinity로 중요 VM 분산 배치                                 │  │
│   │  → GPU 호스트 장애 시: GPU VM 다른 GPU 호스트로 이전                 │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   Level 2: Rack (랙) - 설계 문서용                                         │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  랙 단위 장애 (전원, 네트워크) 시 해당 랙의 모든 호스트 영향         │  │
│   │  → 중요 서비스는 다른 랙에 분산 (실제 구현 시)                       │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   데모 환경 적용:                                                           │
│   - Host 레벨 Anti-Affinity 적용                                           │
│   - 호스트 장애 시 VM 자동 재시작 (다른 호스트에서)                         │
│   - GPU 호스트 장애 시: 학습 작업 체크포인트 후 재개                        │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 4. 리소스 쿼터

### 4.1 쿼터 정책

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        리소스 쿼터 설계                                      │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   가용 자원 (상한):                                                         │
│   - CPU: 100 코어                                                          │
│   - Memory: 2 TiB (2,048 GB)                                               │
│   - GPU: 8개 (또는 vGPU 분할) - 설계 기준                                  │
│                                                                             │
│   AI 플랫폼 데모 환경 할당:                                                 │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │                                                                     │  │
│   │   [테넌트 데이터 영역] - 선택적 (업무 시스템 아님)                  │  │
│   │   테넌트 A (수원시): 데이터 업로드 VM 1대 (2vCPU/4GB, 선택)        │  │
│   │   테넌트 B (성남시): 데이터 업로드 VM 1대 (2vCPU/4GB, 선택)        │  │
│   │   테넌트 C (용인시): API 접근만 (VM 없음)                          │  │
│   │                                                                     │  │
│   │   [공용 AI 플랫폼] - 핵심 인프라                                    │  │
│   │   학습 서버: vCPU 16개, Memory 64GB, VM 2대, GPU 4개 (Passthrough) │  │
│   │   추론 서버: vCPU 8개, Memory 32GB, VM 2대, vGPU 4개               │  │
│   │   품질 게이트: vCPU 4개, Memory 8GB, VM 2대                        │  │
│   │                                                                     │  │
│   │   [관리/운영]                                                       │  │
│   │   DB/API/모니터링: vCPU 8개, Memory 16GB, VM 4대                   │  │
│   │   ─────────────────────────────────────────────────────────────    │  │
│   │   합계: vCPU ~42개, Memory ~132GB, VM ~12대, GPU ~8개              │  │
│   │   ※ 테넌트 웹/앱/DB 서버 없음 (범위 제외)                          │  │
│   │                                                                     │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 4.2 AI 플랫폼 리소스 할당

> **핵심 변경**: 테넌트는 VM을 직접 소유하지 않고, 공용 AI 플랫폼을 API로 이용한다.

| 구성 요소 | vCPU | Memory | VM 수 | GPU | 디스크 | 용도 |
|----------|------|--------|-------|-----|--------|------|
| **학습 서버** | 16개 | 64 GB | 2대 | 4개 (Passthrough) | 500 GB | 공용 모델 학습 |
| **추론 서버** | 8개 | 32 GB | 2대 | 4개 (vGPU) | 200 GB | 추론 API 서비스 |
| **품질 게이트** | 4개 | 8 GB | 2대 | - | 100 GB | 데이터 검증/익명화 |
| **API Gateway** | 2개 | 4 GB | 2대 | - | 50 GB | 테넌트 API 라우팅 |
| **공용 DB** | 4개 | 8 GB | 1대 | - | 100 GB | 메타데이터 저장 |
| **모니터링** | 2개 | 4 GB | 1대 | - | 80 GB | Prometheus/Grafana |
| **테넌트 데이터 VM** | 2개 | 4 GB | 2대 | - | 50 GB | 데이터 업로드 (선택) |

### 4.3 테넌트 쿼터 (API 사용량 기반)

> 테넌트는 VM 쿼터가 아닌 **API 사용량 쿼터**로 관리된다.

| 테넌트 | API 호출/일 | 공용 GPU 시간/월 | 데이터 업로드 | 비고 |
|--------|------------|-----------------|--------------|------|
| **수원시** | 10,000회 | 100시간 | 50 GB/월 | 데이터 업로드 VM 선택 |
| **성남시** | 10,000회 | 100시간 | 50 GB/월 | 데이터 업로드 VM 선택 |
| **용인시** | 5,000회 | 50시간 | 30 GB/월 | API 접근만 |

### 4.4 GPU 할당 상세

| 할당 대상 | GPU 유형 | GPU 수/메모리 | 용도 |
|----------|---------|--------------|------|
| **공용 학습 서버** | Passthrough | 4개 / 전체 | 민원 분류 모델 학습 |
| **공용 추론 서버** | vGPU | 4개 / 8GB×4 | 추론 API 서비스 |
| **테넌트 전용 GPU** | 없음 | - | 공용 GPU 풀 사용 |

### 4.5 쿼터 초과 정책

| 상황 | 정책 |
|------|------|
| API 호출 쿼터 80% 도달 | 테넌트 관리자 경고 알림 |
| API 호출 쿼터 100% 도달 | 추가 API 호출 차단 |
| GPU 시간 쿼터 100% 도달 | 학습 작업 큐 대기 |
| 데이터 업로드 쿼터 초과 | 업로드 차단 |
| GPU 작업 시간 초과 | 체크포인트 후 대기열로 이동 |

---

## 5. 고가용성(HA) 설계

### 5.1 HA 전략

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        고가용성 설계                                         │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   일반 VM 장애 시나리오:                                                    │
│                                                                             │
│   [정상 상태]                      [장애 발생]                              │
│   ┌─────────┐  ┌─────────┐        ┌─────────┐  ┌─────────┐               │
│   │ Host 1  │  │ Host 2  │        │ Host 1  │  │ Host 2  │               │
│   │ ┌─────┐ │  │ ┌─────┐ │        │   ✗     │  │ ┌─────┐ │               │
│   │ │VM-A │ │  │ │VM-B │ │   ──►  │ 장애!   │  │ │VM-B │ │               │
│   │ └─────┘ │  │ └─────┘ │        │         │  │ │VM-A │ │ ← 자동 이전   │
│   └─────────┘  └─────────┘        └─────────┘  │ └─────┘ │               │
│                                                └─────────┘               │
│                                                                             │
│   GPU 호스트 장애 시나리오:                                                 │
│                                                                             │
│   [정상 상태]                      [장애 발생]                              │
│   ┌─────────┐  ┌─────────┐        ┌─────────┐  ┌─────────┐               │
│   │GPU Host1│  │GPU Host2│        │GPU Host1│  │GPU Host2│               │
│   │ ┌─────┐ │  │ ┌─────┐ │        │   ✗     │  │ ┌─────┐ │               │
│   │ │Train│ │  │ │Infer│ │   ──►  │ 장애!   │  │ │Infer│ │               │
│   │ └─────┘ │  │ └─────┘ │        │         │  │ │Train│ │ ← 체크포인트  │
│   └─────────┘  └─────────┘        └─────────┘  │ └─────┘ │   후 재개     │
│                                                └─────────┘               │
│                                                                             │
│   HA 동작 순서:                                                             │
│   1. 호스트 장애 감지 (하트비트 타임아웃)                                   │
│   2. 해당 호스트의 VM 목록 확인                                             │
│   3. 다른 호스트에서 VM 재시작                                              │
│   4. 네트워크/스토리지 재연결                                               │
│   5. GPU VM: 체크포인트에서 학습 재개                                       │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 5.2 HA 설정

| 설정 항목 | 값 | 설명 |
|----------|-----|------|
| **HA 활성화** | 예 | 클러스터 레벨 HA 활성화 |
| **장애 감지 시간** | 30초 | 하트비트 타임아웃 |
| **자동 재시작** | 예 | 장애 VM 자동 재시작 |
| **재시작 우선순위** | High/Medium/Low | VM별 우선순위 설정 |
| **GPU VM 재시작** | 체크포인트 기반 | 학습 상태 보존 후 재개 |

### 5.3 Live Migration

| 항목 | 설명 |
|------|------|
| **목적** | 서비스 중단 없이 VM을 다른 호스트로 이동 |
| **사용 시점** | 호스트 유지보수, 부하 분산 |
| **요구 사항** | 공유 스토리지 (Ceph), 동일 CPU 아키텍처 |
| **GPU VM** | vGPU는 Migration 지원, Passthrough는 중단 필요 |

```
Live Migration 프로세스:

   Host 1                              Host 2
   ┌─────────┐                        ┌─────────┐
   │ [VM-A]  │  ──── 메모리 복사 ────► │ [VM-A'] │
   │ Running │                        │ 준비 중 │
   └─────────┘                        └─────────┘
        │                                  │
        │         ◄── 최종 동기화 ──►       │
        │                                  │
   ┌─────────┐                        ┌─────────┐
   │   ---   │                        │ [VM-A]  │
   │ 종료됨  │                        │ Running │
   └─────────┘                        └─────────┘

   - 다운타임: 수 초 이내
   - 스토리지: Ceph RBD (공유)
   - GPU vGPU: 지원 (NVIDIA GRID)
   - GPU Passthrough: 미지원 (중단 후 재할당 필요)
```

---

## 6. GPU 가상화 설계

### 6.1 GPU 가상화 전략

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        GPU 가상화 전략                                       │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   본 프로젝트는 다음 GPU 가상화 방식을 선택적으로 적용한다:                  │
│                                                                             │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  1. 학습용: GPU Passthrough                                         │  │
│   │  ─────────────────────────────────────────────────────────────────  │  │
│   │  • 대규모 모델 학습에 100% 성능 필요                                │  │
│   │  • 단일 VM에 전체 GPU 할당                                          │  │
│   │  • Live Migration 불가 (유지보수 시 작업 중단 필요)                  │  │
│   │                                                                     │  │
│   │  적용 대상: 공용 AI 플랫폼 학습 서버                                │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  2. 추론/테넌트용: vGPU (NVIDIA GRID)                               │  │
│   │  ─────────────────────────────────────────────────────────────────  │  │
│   │  • 다수 VM에 GPU 공유                                               │  │
│   │  • 프로파일 기반 메모리 분할 (4GB, 8GB, 16GB 등)                    │  │
│   │  • Live Migration 지원                                              │  │
│   │  • 라이선스 필요 (NVIDIA GRID)                                      │  │
│   │                                                                     │  │
│   │  적용 대상: 추론 서버, 테넌트 AI VM                                 │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  3. 개발/테스트용: Time-slicing (옵션)                              │  │
│   │  ─────────────────────────────────────────────────────────────────  │  │
│   │  • 라이선스 없이 GPU 공유                                           │  │
│   │  • 성능 예측 어려움                                                 │  │
│   │  • 개발 환경에서만 사용                                             │  │
│   │                                                                     │  │
│   │  적용 대상: 개발/테스트 환경                                        │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 6.2 vGPU 프로파일 설계

| 프로파일 ID | VRAM | 용도 | 최대 VM 수 (24GB GPU) |
|-------------|------|------|---------------------|
| **PROF-4Q** | 4 GB | 경량 추론, 개발 | 6개 |
| **PROF-8Q** | 8 GB | 일반 추론, 테넌트 | 3개 |
| **PROF-12Q** | 12 GB | 대형 모델 추론 | 2개 |
| **PROF-16Q** | 16 GB | 파인튜닝, 중간 학습 | 1개 |
| **PROF-24Q** | 24 GB | 전체 GPU (vGPU 모드) | 1개 |

### 6.3 GPU 호스트 구성

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        GPU 호스트 구성 (설계)                                │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   GPU Host 1 (학습 전용)                                                    │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  GPU #0: Passthrough → 학습 VM 1                                    │  │
│   │  GPU #1: Passthrough → 학습 VM 2                                    │  │
│   │  GPU #2: Passthrough → (예비 / 버스트 학습)                         │  │
│   │  GPU #3: Passthrough → (예비 / 버스트 학습)                         │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   GPU Host 2 (추론 + 테넌트)                                                │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  GPU #0: vGPU (GRID)                                                │  │
│   │          ├── 추론 VM 1: PROF-8Q (8GB)                               │  │
│   │          ├── 추론 VM 2: PROF-8Q (8GB)                               │  │
│   │          └── 추론 VM 3: PROF-8Q (8GB)                               │  │
│   │                                                                     │  │
│   │  GPU #1: vGPU (GRID)                                                │  │
│   │          ├── 테넌트 A AI VM: PROF-8Q (8GB)                          │  │
│   │          ├── 테넌트 B AI VM: PROF-8Q (8GB)                          │  │
│   │          └── 공용 (대기): PROF-8Q (8GB)                             │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   총 GPU: 6개 (학습 4개 + 추론/테넌트 2개)                                 │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 6.4 GPU 드라이버 및 소프트웨어 스택

| 계층 | 컴포넌트 | 버전 (예시) |
|------|---------|-----------|
| **Host** | NVIDIA Driver | 535.x |
| **Host** | NVIDIA GRID vGPU Manager | 16.x |
| **Guest** | NVIDIA vGPU Guest Driver | 535.x |
| **Guest** | CUDA Toolkit | 12.x |
| **Guest** | cuDNN | 8.x |
| **Guest** | PyTorch/TensorFlow | 최신 |

---

## 7. GPU 스케줄링 및 할당 정책

### 7.1 GPU 스케줄링 아키텍처

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        GPU 스케줄링 아키텍처                                 │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │                     작업 요청 큐 (Job Queue)                        │  │
│   │                                                                     │  │
│   │   [긴급 추론]  [일반 추론]  [파인튜닝]  [대규모 학습]              │  │
│   │   Priority:1   Priority:2   Priority:3   Priority:4                 │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                    │                                        │
│                                    ▼                                        │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │                        GPU 스케줄러                                 │  │
│   │  ─────────────────────────────────────────────────────────────────  │  │
│   │                                                                     │  │
│   │  1. 테넌트 쿼터 확인                                                │  │
│   │     → 테넌트별 GPU 할당량 내인지 확인                              │  │
│   │                                                                     │  │
│   │  2. Fair-Share 계산                                                 │  │
│   │     → 테넌트별 공정한 GPU 시간 배분                                │  │
│   │                                                                     │  │
│   │  3. 우선순위 적용                                                   │  │
│   │     → 긴급 추론 > 일반 추론 > 학습                                 │  │
│   │                                                                     │  │
│   │  4. GPU 풀 선택                                                     │  │
│   │     → 학습: Passthrough 풀 / 추론: vGPU 풀                         │  │
│   │                                                                     │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                    │                                        │
│               ┌────────────────────┴────────────────────┐                  │
│               ▼                                          ▼                  │
│   ┌─────────────────────────┐            ┌─────────────────────────┐      │
│   │    학습 GPU 풀          │            │    추론 GPU 풀          │      │
│   │    (Passthrough)        │            │    (vGPU)               │      │
│   │    ┌─────┐ ┌─────┐     │            │    ┌─────┐ ┌─────┐     │      │
│   │    │GPU0 │ │GPU1 │     │            │    │GPU0 │ │GPU1 │     │      │
│   │    │ 전용│ │ 전용│     │            │    │8Gx3 │ │8Gx3 │     │      │
│   │    └─────┘ └─────┘     │            │    └─────┘ └─────┘     │      │
│   └─────────────────────────┘            └─────────────────────────┘      │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 7.2 할당 정책

| 정책 항목 | 설정 | 설명 |
|----------|------|------|
| **테넌트 쿼터** | vGPU 1~2개 / 테넌트 | 테넌트별 전용 vGPU 할당 |
| **공용 풀 쿼터** | Fair-Share | GPU 시간 기반 공정 배분 |
| **우선순위** | 4단계 | 긴급추론(1) → 일반추론(2) → 파인튜닝(3) → 학습(4) |
| **최대 작업 시간** | 학습 24시간, 추론 무제한 | 학습은 시간 제한, 추론은 상시 |
| **선점 정책** | 체크포인트 후 선점 | 긴급 작업 위해 학습 일시 중단 |
| **대기열** | Priority FIFO | 우선순위 내 FIFO |

### 7.3 GPU 모니터링 메트릭

| 메트릭 | 수집 주기 | 임계치 | 알림 |
|--------|----------|--------|------|
| **GPU Utilization** | 10초 | 90% 이상 5분 지속 | Warning |
| **GPU Memory Usage** | 10초 | 95% 이상 | Critical |
| **GPU Temperature** | 30초 | 85°C 이상 | Critical |
| **GPU Power** | 30초 | TDP 초과 | Warning |
| **vGPU Scheduler Latency** | 10초 | 100ms 이상 | Warning |

---

## 8. VM 템플릿 및 표준화

### 8.1 VM 템플릿 목록 (AI 플랫폼 전용)

| 템플릿 ID | OS | 스펙 | GPU | 용도 | 포함 패키지 |
|----------|-----|------|-----|------|------------|
| **TPL-AI-TRAIN** | Ubuntu 22.04 | 8vCPU/32GB | Passthrough | AI 학습 | CUDA, PyTorch, dcgm-exporter |
| **TPL-AI-INFER** | Ubuntu 22.04 | 4vCPU/16GB | vGPU (8GB) | AI 추론 | CUDA, TensorRT, dcgm-exporter |
| **TPL-QUALITY-GATE** | Ubuntu 22.04 | 2vCPU/4GB | - | 품질 게이트 | python, pandas, pii-detector |
| **TPL-DATA-UPLOAD** | Ubuntu 22.04 | 2vCPU/4GB | - | 데이터 업로드 (테넌트) | sftp, rsync |
| **TPL-API-GW** | Ubuntu 22.04 | 2vCPU/4GB | - | API Gateway | nginx, kong |
| **TPL-DB** | Ubuntu 22.04 | 4vCPU/8GB | - | 공용 DB | postgresql, node_exporter |
| **TPL-MON** | Ubuntu 22.04 | 2vCPU/4GB | - | 모니터링 | prometheus, grafana |

> **참고**: 테넌트 웹/앱 서버 템플릿(TPL-WEB, TPL-APP)은 본 프로젝트 범위에서 제외됨

### 8.2 AI VM 템플릿 구성 상세

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        AI VM 템플릿 구성                                     │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   TPL-AI-TRAIN (학습용):                                                    │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  - Ubuntu 22.04 LTS                                                 │  │
│   │  - NVIDIA Driver 535.x                                              │  │
│   │  - CUDA Toolkit 12.x                                                │  │
│   │  - cuDNN 8.x                                                        │  │
│   │  - PyTorch 2.x / TensorFlow 2.x                                     │  │
│   │  - Horovod (분산 학습)                                              │  │
│   │  - dcgm-exporter (GPU 메트릭)                                       │  │
│   │  - 대용량 로컬 NVMe (체크포인트용)                                  │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   TPL-AI-INFER (추론용):                                                    │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  - Ubuntu 22.04 LTS                                                 │  │
│   │  - NVIDIA Driver 535.x (vGPU Guest)                                 │  │
│   │  - CUDA Toolkit 12.x                                                │  │
│   │  - TensorRT (최적화 추론)                                           │  │
│   │  - Triton Inference Server                                          │  │
│   │  - dcgm-exporter (GPU 메트릭)                                       │  │
│   │  - 모델 캐시 볼륨 마운트                                            │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   Cloud-init 설정 (AI VM):                                                  │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  #cloud-config                                                      │  │
│   │  hostname: ${vm_name}                                               │  │
│   │  timezone: Asia/Seoul                                               │  │
│   │  mounts:                                                            │  │
│   │    - ["/dev/vdb", "/data/training", "ext4", "defaults", "0", "2"]   │  │
│   │  runcmd:                                                            │  │
│   │    - nvidia-smi                                                     │  │
│   │    - systemctl enable dcgm-exporter                                 │  │
│   │    - systemctl start dcgm-exporter                                  │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 8.3 VM 명명 규칙

```
{환경}-{테넌트/용도}-{역할}-{번호}

예시:
- dev-a-web-01      : 개발환경, 테넌트A, 웹서버, 1번
- dev-b-app-01      : 개발환경, 테넌트B, 앱서버, 1번
- dev-a-ai-01       : 개발환경, 테넌트A, AI VM, 1번
- dev-shared-train-01 : 개발환경, 공용, 학습서버, 1번
- dev-shared-infer-01 : 개발환경, 공용, 추론서버, 1번
- dev-mgmt-mon-01   : 개발환경, 관리, 모니터링, 1번
```

---

## 9. 검증 워크로드 배포 계획

### 9.1 검증 목적

> 인프라 설계의 정상 동작을 확인하기 위한 샘플 워크로드 배포

| 검증 항목 | 검증 방법 |
|----------|----------|
| **테넌트 격리** | 테넌트 간 네트워크/GPU 접근 불가 확인 |
| **리소스 쿼터** | 쿼터 초과 시 VM/GPU 생성 차단 확인 |
| **HA** | 호스트 장애 시 VM 자동 재시작 확인 |
| **Anti-Affinity** | VM이 다른 호스트에 분산되었는지 확인 |
| **GPU 할당** | vGPU 정상 할당 및 추론 동작 확인 |
| **GPU 스케줄링** | 작업 큐잉 및 Fair-Share 동작 확인 |

### 9.2 검증 환경 VM 구성 (AI 플랫폼 중심)

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                   AI 플랫폼 검증 워크로드 배포 구성                            │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   [계층 1: 테넌트 데이터 영역] - 최소 구성                                   │
│   ┌─────────────────┐       ┌─────────────────┐       ┌─────────────────┐  │
│   │ dev-a-upload-01 │       │ dev-b-upload-01 │       │   (VM 없음)     │  │
│   │ (2vCPU/4GB)     │       │ (2vCPU/4GB)     │       │   용인시는      │  │
│   │ 데이터 업로드   │       │ 데이터 업로드   │       │   API 접근만    │  │
│   │ 수원시          │       │ 성남시          │       │                 │  │
│   └─────────────────┘       └─────────────────┘       └─────────────────┘  │
│         │                         │                                         │
│         └─────────────────────────┼─────────────────────────────────────┐  │
│                                   ▼                                      │  │
│   [계층 2: 품질 게이트]                                                    │  │
│   ┌─────────────────┐       ┌─────────────────┐                          │  │
│   │ dev-qgate-01    │       │ dev-qgate-02    │                          │  │
│   │ (2vCPU/4GB)     │       │ (2vCPU/4GB)     │                          │  │
│   │ 데이터 검증     │       │ PII 익명화     │                          │  │
│   └─────────────────┘       └─────────────────┘                          │  │
│                                   │                                      │  │
│                                   ▼                                      │  │
│   [계층 3: 공용 AI 플랫폼]                                                 │  │
│   ┌─────────────────┐       ┌─────────────────┐       ┌─────────────────┐│  │
│   │dev-ai-train-01  │       │dev-ai-infer-01  │       │dev-ai-infer-02  ││  │
│   │ (8vCPU/32GB)    │       │ (4vCPU/16GB)    │       │ (4vCPU/16GB)    ││  │
│   │ GPU Passthrough │       │ vGPU 8GB        │       │ vGPU 8GB        ││  │
│   │ 민원분류 학습   │       │ 추론 서비스 #1  │       │ 추론 서비스 #2  ││  │
│   └─────────────────┘       └─────────────────┘       └─────────────────┘│  │
│                                   │                                      │  │
│                                   ▼                                      │  │
│   [계층 4: 서비스 계층]                                                    │  │
│   ┌─────────────────┐       ┌─────────────────┐       ┌─────────────────┐│  │
│   │ dev-api-gw-01   │       │ dev-mgmt-db-01  │       │ dev-mgmt-mon-01 ││  │
│   │ (2vCPU/4GB)     │       │ (4vCPU/8GB)     │       │ (2vCPU/4GB)     ││  │
│   │ API Gateway     │       │ PostgreSQL      │       │ Prometheus      ││  │
│   │ 테넌트 라우팅   │       │ 메타데이터 DB   │       │ Grafana         ││  │
│   └─────────────────┘       └─────────────────┘       └─────────────────┘│  │
│                                                                          │  │
│   총 VM: ~10대 (데이터업로드 2대 + 품질게이트 2대 + AI 3대 + 관리 3대)   │  │
│   총 GPU: ~4개 (학습 Passthrough 2개 + 추론 vGPU 2개)                    │  │
│   ※ 테넌트 웹/앱/DB 서버 없음 (범위 제외)                                 │  │
│                                                                          │  │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 9.3 검증 시나리오

| 시나리오 | 절차 | 예상 결과 |
|----------|------|----------|
| **SC-01: 테넌트 격리** | 테넌트 A VM에서 테넌트 B VM ping | 연결 실패 (차단) |
| **SC-02: 쿼터 테스트** | 테넌트 A에서 쿼터 초과 VM 생성 시도 | 생성 실패 |
| **SC-03: HA 테스트** | 호스트 장애 시뮬레이션 | VM 자동 재시작 |
| **SC-04: Anti-Affinity** | 동일 서비스 VM 배치 확인 | 다른 호스트에 분산 |
| **SC-05: GPU 할당** | 테넌트 AI VM에서 vGPU 확인 | nvidia-smi 정상 출력 |
| **SC-06: GPU 격리** | 테넌트 A GPU에서 테넌트 B 메모리 접근 | 접근 불가 |
| **SC-07: GPU 스케줄링** | 동시 GPU 작업 제출 | Fair-Share 배분 |
| **SC-08: AI 추론 테스트** | 추론 API 호출 | 정상 응답 |

### 9.4 검증 AI 워크로드: 민원 자동 분류

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                   민원 자동 분류 AI 워크로드 (검증용)                         │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   목표 서비스: 민원 자동 분류                                               │
│   - 기능: 민원 접수 시 담당 부서 자동 분류                                  │
│   - 기술: 텍스트 분류 모델 (BERT 기반)                                      │
│   - 구현 수준: 인프라 검증용 샘플 워크로드                                  │
│                                                                             │
│   1. 학습 워크로드                                                          │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  - 모델: KoBERT 또는 KLUE-BERT 기반 텍스트 분류                     │  │
│   │  - 데이터: 샘플 민원 데이터 (시뮬레이션)                            │  │
│   │  - 분류 카테고리: 5~10개 부서                                       │  │
│   │  - 학습 시간: 1~2시간 (데모 규모)                                   │  │
│   │  - GPU: Passthrough (학습 서버)                                     │  │
│   │  - 체크포인트: Ceph 저장                                            │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   2. 추론 워크로드                                                          │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  - REST API: /api/v1/classify                                       │  │
│   │  - 입력: 민원 텍스트                                                │  │
│   │  - 출력: 담당 부서, 신뢰도 점수                                     │  │
│   │  - 지연 시간 목표: <200ms                                           │  │
│   │  - GPU: vGPU 8GB (추론 서버)                                        │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   3. 4계층 데이터 흐름 검증                                                 │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  [테넌트] 민원 데이터 업로드                                        │  │
│   │      ↓                                                              │  │
│   │  [품질 게이트] PII 마스킹, 데이터 검증                              │  │
│   │      ↓                                                              │  │
│   │  [AI 플랫폼] 학습 데이터에 추가, 모델 재학습 (주기적)               │  │
│   │      ↓                                                              │  │
│   │  [서비스 계층] 추론 API 호출 → 분류 결과 반환                       │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 변경 이력

| 버전 | 날짜 | 변경 내용 | 작성자 |
|------|------|----------|--------|
| 1.0 | 2026-01-30 | 초안 작성 | - |
| 2.0 | 2026-02-02 | **GPU 가상화 통합**: GPU 설계, vGPU 프로파일, GPU 스케줄링, AI VM 템플릿 추가 | - |
| 3.0 | 2026-02-04 | **AI 플랫폼 중심 재구성**: 테넌트 웹/앱/DB 범위 제외, 테넌트 역할을 API 사용량 쿼터로 변경, 민원 자동 분류 워크로드 명확화 | - |

---

## 관련 문서

- [01_프로젝트_개요서.md](01_프로젝트_개요서.md)
- [02_팀_역할분담.md](02_팀_역할분담.md)
- [03_상세설계_가이드.md](03_상세설계_가이드.md)
- [05_네트워크_보안_설계서.md](05_네트워크_보안_설계서.md)
- [06_스토리지_설계서.md](06_스토리지_설계서.md)
