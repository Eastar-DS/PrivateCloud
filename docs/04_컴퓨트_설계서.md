# 컴퓨트 설계서

## 범정부 차세대 AI 공동 활용 인프라 구축 프로젝트
### 공공 데이터 주권 확보를 위한 멀티테넌트 프라이빗 클라우드 설계

| 항목 | 내용 |
|------|------|
| 문서명 | 컴퓨트 설계서 |
| 버전 | 2.0 |
| 작성일 | 2026-02-02 |
| 담당팀 | 컴퓨트/개발 팀 |

---

**목차**

1. [설계 개요 및 목표](#1-설계-개요-및-목표)
2. [리소스 풀 설계](#2-리소스-풀-설계)
3. [VM 배치 전략](#3-vm-배치-전략)
4. [리소스 쿼터](#4-리소스-쿼터)
5. [고가용성(HA) 설계](#5-고가용성ha-설계)
6. [GPU 가상화 설계](#6-gpu-가상화-설계)
7. [GPU 스케줄링 및 할당 정책](#7-gpu-스케줄링-및-할당-정책)
8. [VM 템플릿 및 표준화](#8-vm-템플릿-및-표준화)
9. [검증 워크로드 배포 계획](#9-검증-워크로드-배포-계획)

---

## 1. 설계 개요 및 목표

### 1.1 설계 목표

| 목표 | 설명 | 검증 방법 |
|------|------|----------|
| **테넌트 격리** | 테넌트별 컴퓨트/GPU 리소스 격리 | 쿼터 적용 확인 |
| **고가용성** | VM 장애 시 자동 복구 | Failover 테스트 |
| **자원 효율성** | 리소스 풀링으로 효율적 활용 | 활용률 모니터링 |
| **GPU 공유** | 멀티테넌트 GPU 자원 공유 | vGPU 할당 확인 |
| **표준화** | VM 템플릿으로 일관된 환경 | 템플릿 기반 배포 |

### 1.2 설계 범위

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        컴퓨트 설계 범위                                       │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   In-Scope (담당 영역)                                                      │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  - 리소스 풀 구성 및 관리                                            │  │
│   │  - VM 배치 전략 (Affinity/Anti-Affinity)                            │  │
│   │  - 장애 도메인 설계                                                  │  │
│   │  - 리소스 쿼터 정책 (CPU/Memory/GPU)                                 │  │
│   │  - HA 설정 (VM 자동 재시작, Live Migration)                         │  │
│   │  - GPU 가상화 설계 (vGPU, MIG, Passthrough) [신규]                  │  │
│   │  - GPU 스케줄링 및 할당 정책 [신규]                                  │  │
│   │  - VM 템플릿 관리 (일반 + AI VM) [확장]                             │  │
│   │  - 검증 워크로드 배포 (웹앱 + AI 워크로드) [확장]                   │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   협업 영역 (다른 팀과 공동)                                                │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  - VM 네트워크 연결 (네트워크 팀)                                    │  │
│   │  - VM 스토리지 볼륨 (스토리지 팀)                                    │  │
│   │  - GPU VM AI 스토리지 연결 (스토리지 팀) [신규]                     │  │
│   │  - 모니터링 에이전트 (공통)                                          │  │
│   │  - GPU 메트릭 수집 (공통) [신규]                                    │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 2. 리소스 풀 설계

### 2.1 풀 구성 전략

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        리소스 풀 구조                                        │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│                         ┌─────────────────┐                                │
│                         │   Root Pool     │                                │
│                         │  (전체 클러스터) │                                │
│                         └────────┬────────┘                                │
│                                  │                                          │
│     ┌────────────────────────────┼────────────────────────────┐            │
│     │                            │                            │            │
│     ▼                            ▼                            ▼            │
│   ┌─────────────┐         ┌─────────────┐         ┌─────────────┐         │
│   │ 테넌트 풀   │         │ 공용 서비스 │         │ 관리 풀     │         │
│   │ (A, B, C)   │         │ 풀 (GPU 포함)│         │ (운영)      │         │
│   └──────┬──────┘         └──────┬──────┘         └─────────────┘         │
│          │                       │                                         │
│          │                ┌──────┴──────┐                                  │
│          │                │             │                                  │
│          ▼                ▼             ▼                                  │
│   ┌─────────────┐  ┌─────────────┐ ┌─────────────┐                        │
│   │ 일반 VM    │  │ GPU 학습   │ │ GPU 추론   │                        │
│   │ (웹/앱)    │  │ 풀         │ │ 풀         │                        │
│   └─────────────┘  └─────────────┘ └─────────────┘                        │
│                                                                             │
│   테넌트 풀: 각 테넌트 VM 실행 (일반 + AI VM)                              │
│   GPU 학습 풀: 대규모 모델 학습용 (Passthrough)                            │
│   GPU 추론 풀: 추론 서비스용 (vGPU 공유)                                   │
│   관리 풀: 플랫폼 관리 VM                                                   │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 2.2 오버커밋 정책

| 리소스 | 오버커밋 비율 | 설명 |
|--------|-------------|------|
| **CPU** | 2:1 | 물리 1코어당 가상 2코어 할당 가능 |
| **Memory** | 1:1 | 메모리는 오버커밋 없음 (안정성) |
| **GPU** | 오버커밋 없음 | GPU 메모리는 정확한 할당 필요 |
| **Storage** | Thin Provisioning | 실제 사용량만 할당 |

**오버커밋 설정 근거:**
- CPU는 일반적으로 100% 사용되지 않으므로 2:1 오버커밋 적용
- Memory는 스왑 발생 시 성능 저하가 심하므로 오버커밋 없음
- GPU는 VRAM 부족 시 OOM 발생하므로 오버커밋 불가
- 스토리지는 Thin Provisioning으로 효율적 활용

### 2.3 클러스터 구성

| 구성 요소 | 수량 | 설명 |
|----------|------|------|
| **Zone** | 1개 | 단일 데이터센터 |
| **Pod** | 1개 | 네트워크 도메인 |
| **Cluster** | 1개 | 호스트 그룹 |
| **Host** | 가용 호스트 | HCI 노드 |
| **GPU Host** | 1~2개 (설계) | GPU 장착 노드 |

---

## 3. VM 배치 전략

### 3.1 Affinity / Anti-Affinity

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                     Affinity / Anti-Affinity 규칙                           │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   Anti-Affinity (분산 배치) - HA 목적                                       │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │                                                                     │  │
│   │   Host 1              Host 2              Host 3 (GPU)             │  │
│   │   ┌─────────┐        ┌─────────┐        ┌─────────┐                │  │
│   │   │ Web-A1  │        │ Web-A2  │        │ AI-Inf  │                │  │
│   │   │ (테넌트A)│        │ (테넌트A)│        │ (추론)  │                │  │
│   │   └─────────┘        └─────────┘        └─────────┘                │  │
│   │                                                                     │  │
│   │   ✓ 동일 서비스 VM은 다른 호스트에 분산 → 호스트 장애 시 서비스 유지 │  │
│   │                                                                     │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   Affinity (동일 배치) - 성능/GPU 목적                                      │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │                                                                     │  │
│   │   GPU Host 1                                                        │  │
│   │   ┌─────────┐  ┌─────────┐  ┌─────────┐                            │  │
│   │   │Train-A │──│Train-B │──│Train-C │  ← 분산 학습 VM은 동일 GPU호스트│  │
│   │   │(GPU #0)│  │(GPU #1)│  │(GPU #2)│                               │  │
│   │   └─────────┘  └─────────┘  └─────────┘                            │  │
│   │                                                                     │  │
│   │   ✓ GPU 간 고속 통신 (NVLink/PCIe)                                  │  │
│   │                                                                     │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 3.2 배치 규칙 정의

| 규칙 ID | 유형 | 대상 VM | 설명 |
|---------|------|--------|------|
| **AA-001** | Anti-Affinity | 웹서버 (동일 테넌트) | HA를 위해 분산 배치 |
| **AA-002** | Anti-Affinity | DB Primary/Standby | 장애 격리 |
| **AA-003** | Anti-Affinity | 추론 서버 | 서비스 HA |
| **AF-001** | Affinity | App-Cache 쌍 | 레이턴시 최소화 |
| **AF-002** | Affinity | 분산 학습 VM | GPU 간 고속 통신 |
| **GPU-001** | GPU Host Only | AI 학습/추론 VM | GPU 호스트에만 배치 |

### 3.3 장애 도메인 분리

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        장애 도메인 설계                                      │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   장애 도메인 레벨:                                                         │
│                                                                             │
│   Level 1: Host (호스트)                                                    │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  단일 호스트 장애 시 해당 호스트의 VM만 영향                         │  │
│   │  → Anti-Affinity로 중요 VM 분산 배치                                 │  │
│   │  → GPU 호스트 장애 시: GPU VM 다른 GPU 호스트로 이전                 │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   Level 2: Rack (랙) - 설계 문서용                                         │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  랙 단위 장애 (전원, 네트워크) 시 해당 랙의 모든 호스트 영향         │  │
│   │  → 중요 서비스는 다른 랙에 분산 (실제 구현 시)                       │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   데모 환경 적용:                                                           │
│   - Host 레벨 Anti-Affinity 적용                                           │
│   - 호스트 장애 시 VM 자동 재시작 (다른 호스트에서)                         │
│   - GPU 호스트 장애 시: 학습 작업 체크포인트 후 재개                        │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 4. 리소스 쿼터

### 4.1 쿼터 정책

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        리소스 쿼터 설계                                      │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   가용 자원 (상한):                                                         │
│   - CPU: 100 코어                                                          │
│   - Memory: 2 TiB (2,048 GB)                                               │
│   - GPU: 8개 (또는 vGPU 분할) - 설계 기준                                  │
│                                                                             │
│   데모 환경 할당:                                                           │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │                                                                     │  │
│   │   테넌트 A: vCPU 10개, Memory 24GB, VM 4대, vGPU 1개               │  │
│   │   테넌트 B: vCPU 10개, Memory 24GB, VM 4대, vGPU 1개               │  │
│   │   테넌트 C: vCPU 8개,  Memory 16GB, VM 3대, vGPU (공용)            │  │
│   │   공용 AI:  vCPU 12개, Memory 56GB, VM 4대, GPU 4개 (학습+추론)    │  │
│   │   관리/운영: vCPU 8개, Memory 16GB, VM 4대                          │  │
│   │   ─────────────────────────────────────────────────────────────    │  │
│   │   합계:    vCPU ~48개, Memory ~136GB, VM ~19대, GPU ~6개           │  │
│   │                                                                     │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 4.2 테넌트별 쿼터 상세

| 테넌트 | vCPU | Memory | VM 수 | vGPU | 디스크 | 용도 |
|--------|------|--------|-------|------|--------|------|
| **테넌트 A** | 10개 | 24 GB | 4대 | 1개 (8GB) | 150 GB | A시청 업무 + AI |
| **테넌트 B** | 10개 | 24 GB | 4대 | 1개 (8GB) | 150 GB | B구청 업무 + AI |
| **테넌트 C** | 8개 | 16 GB | 3대 | 공용 | 100 GB | C군청 업무 |
| **공용 AI** | 12개 | 56 GB | 4대 | 4개 | 500 GB | 학습/추론 서비스 |
| **관리/운영** | 8개 | 16 GB | 4대 | - | 120 GB | 모니터링, 관리 |

### 4.3 GPU 쿼터 상세

| 할당 대상 | GPU 유형 | GPU 수/메모리 | 용도 |
|----------|---------|--------------|------|
| **테넌트 A** | vGPU | 1개 / 8GB | 테넌트 특화 모델, 경량 학습 |
| **테넌트 B** | vGPU | 1개 / 8GB | 테넌트 특화 모델, 경량 학습 |
| **테넌트 C** | 공용 GPU 풀 사용 | 시간 할당 | 요청 시 사용 |
| **공용 학습** | Passthrough | 2개 / 전체 | 대규모 모델 학습 |
| **공용 추론** | vGPU | 2개 / 16GB | 추론 서비스 |

### 4.4 쿼터 초과 정책

| 상황 | 정책 |
|------|------|
| CPU/Memory 쿼터 80% 도달 | 경고 알림 발송 |
| CPU/Memory 쿼터 100% 도달 | 신규 VM 생성 차단 |
| GPU 쿼터 100% 도달 | 작업 큐 대기 |
| 기존 VM | 계속 운영 (강제 종료 없음) |
| GPU 작업 시간 초과 | 체크포인트 후 대기열로 이동 |

---

## 5. 고가용성(HA) 설계

### 5.1 HA 전략

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        고가용성 설계                                         │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   일반 VM 장애 시나리오:                                                    │
│                                                                             │
│   [정상 상태]                      [장애 발생]                              │
│   ┌─────────┐  ┌─────────┐        ┌─────────┐  ┌─────────┐               │
│   │ Host 1  │  │ Host 2  │        │ Host 1  │  │ Host 2  │               │
│   │ ┌─────┐ │  │ ┌─────┐ │        │   ✗     │  │ ┌─────┐ │               │
│   │ │VM-A │ │  │ │VM-B │ │   ──►  │ 장애!   │  │ │VM-B │ │               │
│   │ └─────┘ │  │ └─────┘ │        │         │  │ │VM-A │ │ ← 자동 이전   │
│   └─────────┘  └─────────┘        └─────────┘  │ └─────┘ │               │
│                                                └─────────┘               │
│                                                                             │
│   GPU 호스트 장애 시나리오:                                                 │
│                                                                             │
│   [정상 상태]                      [장애 발생]                              │
│   ┌─────────┐  ┌─────────┐        ┌─────────┐  ┌─────────┐               │
│   │GPU Host1│  │GPU Host2│        │GPU Host1│  │GPU Host2│               │
│   │ ┌─────┐ │  │ ┌─────┐ │        │   ✗     │  │ ┌─────┐ │               │
│   │ │Train│ │  │ │Infer│ │   ──►  │ 장애!   │  │ │Infer│ │               │
│   │ └─────┘ │  │ └─────┘ │        │         │  │ │Train│ │ ← 체크포인트  │
│   └─────────┘  └─────────┘        └─────────┘  │ └─────┘ │   후 재개     │
│                                                └─────────┘               │
│                                                                             │
│   HA 동작 순서:                                                             │
│   1. 호스트 장애 감지 (하트비트 타임아웃)                                   │
│   2. 해당 호스트의 VM 목록 확인                                             │
│   3. 다른 호스트에서 VM 재시작                                              │
│   4. 네트워크/스토리지 재연결                                               │
│   5. GPU VM: 체크포인트에서 학습 재개                                       │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 5.2 HA 설정

| 설정 항목 | 값 | 설명 |
|----------|-----|------|
| **HA 활성화** | 예 | 클러스터 레벨 HA 활성화 |
| **장애 감지 시간** | 30초 | 하트비트 타임아웃 |
| **자동 재시작** | 예 | 장애 VM 자동 재시작 |
| **재시작 우선순위** | High/Medium/Low | VM별 우선순위 설정 |
| **GPU VM 재시작** | 체크포인트 기반 | 학습 상태 보존 후 재개 |

### 5.3 Live Migration

| 항목 | 설명 |
|------|------|
| **목적** | 서비스 중단 없이 VM을 다른 호스트로 이동 |
| **사용 시점** | 호스트 유지보수, 부하 분산 |
| **요구 사항** | 공유 스토리지 (Ceph), 동일 CPU 아키텍처 |
| **GPU VM** | vGPU는 Migration 지원, Passthrough는 중단 필요 |

```
Live Migration 프로세스:

   Host 1                              Host 2
   ┌─────────┐                        ┌─────────┐
   │ [VM-A]  │  ──── 메모리 복사 ────► │ [VM-A'] │
   │ Running │                        │ 준비 중 │
   └─────────┘                        └─────────┘
        │                                  │
        │         ◄── 최종 동기화 ──►       │
        │                                  │
   ┌─────────┐                        ┌─────────┐
   │   ---   │                        │ [VM-A]  │
   │ 종료됨  │                        │ Running │
   └─────────┘                        └─────────┘

   - 다운타임: 수 초 이내
   - 스토리지: Ceph RBD (공유)
   - GPU vGPU: 지원 (NVIDIA GRID)
   - GPU Passthrough: 미지원 (중단 후 재할당 필요)
```

---

## 6. GPU 가상화 설계

### 6.1 GPU 가상화 전략

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        GPU 가상화 전략                                       │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   본 프로젝트는 다음 GPU 가상화 방식을 선택적으로 적용한다:                  │
│                                                                             │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  1. 학습용: GPU Passthrough                                         │  │
│   │  ─────────────────────────────────────────────────────────────────  │  │
│   │  • 대규모 모델 학습에 100% 성능 필요                                │  │
│   │  • 단일 VM에 전체 GPU 할당                                          │  │
│   │  • Live Migration 불가 (유지보수 시 작업 중단 필요)                  │  │
│   │                                                                     │  │
│   │  적용 대상: 공용 AI 플랫폼 학습 서버                                │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  2. 추론/테넌트용: vGPU (NVIDIA GRID)                               │  │
│   │  ─────────────────────────────────────────────────────────────────  │  │
│   │  • 다수 VM에 GPU 공유                                               │  │
│   │  • 프로파일 기반 메모리 분할 (4GB, 8GB, 16GB 등)                    │  │
│   │  • Live Migration 지원                                              │  │
│   │  • 라이선스 필요 (NVIDIA GRID)                                      │  │
│   │                                                                     │  │
│   │  적용 대상: 추론 서버, 테넌트 AI VM                                 │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  3. 개발/테스트용: Time-slicing (옵션)                              │  │
│   │  ─────────────────────────────────────────────────────────────────  │  │
│   │  • 라이선스 없이 GPU 공유                                           │  │
│   │  • 성능 예측 어려움                                                 │  │
│   │  • 개발 환경에서만 사용                                             │  │
│   │                                                                     │  │
│   │  적용 대상: 개발/테스트 환경                                        │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 6.2 vGPU 프로파일 설계

| 프로파일 ID | VRAM | 용도 | 최대 VM 수 (24GB GPU) |
|-------------|------|------|---------------------|
| **PROF-4Q** | 4 GB | 경량 추론, 개발 | 6개 |
| **PROF-8Q** | 8 GB | 일반 추론, 테넌트 | 3개 |
| **PROF-12Q** | 12 GB | 대형 모델 추론 | 2개 |
| **PROF-16Q** | 16 GB | 파인튜닝, 중간 학습 | 1개 |
| **PROF-24Q** | 24 GB | 전체 GPU (vGPU 모드) | 1개 |

### 6.3 GPU 호스트 구성

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        GPU 호스트 구성 (설계)                                │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   GPU Host 1 (학습 전용)                                                    │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  GPU #0: Passthrough → 학습 VM 1                                    │  │
│   │  GPU #1: Passthrough → 학습 VM 2                                    │  │
│   │  GPU #2: Passthrough → (예비 / 버스트 학습)                         │  │
│   │  GPU #3: Passthrough → (예비 / 버스트 학습)                         │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   GPU Host 2 (추론 + 테넌트)                                                │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  GPU #0: vGPU (GRID)                                                │  │
│   │          ├── 추론 VM 1: PROF-8Q (8GB)                               │  │
│   │          ├── 추론 VM 2: PROF-8Q (8GB)                               │  │
│   │          └── 추론 VM 3: PROF-8Q (8GB)                               │  │
│   │                                                                     │  │
│   │  GPU #1: vGPU (GRID)                                                │  │
│   │          ├── 테넌트 A AI VM: PROF-8Q (8GB)                          │  │
│   │          ├── 테넌트 B AI VM: PROF-8Q (8GB)                          │  │
│   │          └── 공용 (대기): PROF-8Q (8GB)                             │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   총 GPU: 6개 (학습 4개 + 추론/테넌트 2개)                                 │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 6.4 GPU 드라이버 및 소프트웨어 스택

| 계층 | 컴포넌트 | 버전 (예시) |
|------|---------|-----------|
| **Host** | NVIDIA Driver | 535.x |
| **Host** | NVIDIA GRID vGPU Manager | 16.x |
| **Guest** | NVIDIA vGPU Guest Driver | 535.x |
| **Guest** | CUDA Toolkit | 12.x |
| **Guest** | cuDNN | 8.x |
| **Guest** | PyTorch/TensorFlow | 최신 |

---

## 7. GPU 스케줄링 및 할당 정책

### 7.1 GPU 스케줄링 아키텍처

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        GPU 스케줄링 아키텍처                                 │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │                     작업 요청 큐 (Job Queue)                        │  │
│   │                                                                     │  │
│   │   [긴급 추론]  [일반 추론]  [파인튜닝]  [대규모 학습]              │  │
│   │   Priority:1   Priority:2   Priority:3   Priority:4                 │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                    │                                        │
│                                    ▼                                        │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │                        GPU 스케줄러                                 │  │
│   │  ─────────────────────────────────────────────────────────────────  │  │
│   │                                                                     │  │
│   │  1. 테넌트 쿼터 확인                                                │  │
│   │     → 테넌트별 GPU 할당량 내인지 확인                              │  │
│   │                                                                     │  │
│   │  2. Fair-Share 계산                                                 │  │
│   │     → 테넌트별 공정한 GPU 시간 배분                                │  │
│   │                                                                     │  │
│   │  3. 우선순위 적용                                                   │  │
│   │     → 긴급 추론 > 일반 추론 > 학습                                 │  │
│   │                                                                     │  │
│   │  4. GPU 풀 선택                                                     │  │
│   │     → 학습: Passthrough 풀 / 추론: vGPU 풀                         │  │
│   │                                                                     │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                    │                                        │
│               ┌────────────────────┴────────────────────┐                  │
│               ▼                                          ▼                  │
│   ┌─────────────────────────┐            ┌─────────────────────────┐      │
│   │    학습 GPU 풀          │            │    추론 GPU 풀          │      │
│   │    (Passthrough)        │            │    (vGPU)               │      │
│   │    ┌─────┐ ┌─────┐     │            │    ┌─────┐ ┌─────┐     │      │
│   │    │GPU0 │ │GPU1 │     │            │    │GPU0 │ │GPU1 │     │      │
│   │    │ 전용│ │ 전용│     │            │    │8Gx3 │ │8Gx3 │     │      │
│   │    └─────┘ └─────┘     │            │    └─────┘ └─────┘     │      │
│   └─────────────────────────┘            └─────────────────────────┘      │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 7.2 할당 정책

| 정책 항목 | 설정 | 설명 |
|----------|------|------|
| **테넌트 쿼터** | vGPU 1~2개 / 테넌트 | 테넌트별 전용 vGPU 할당 |
| **공용 풀 쿼터** | Fair-Share | GPU 시간 기반 공정 배분 |
| **우선순위** | 4단계 | 긴급추론(1) → 일반추론(2) → 파인튜닝(3) → 학습(4) |
| **최대 작업 시간** | 학습 24시간, 추론 무제한 | 학습은 시간 제한, 추론은 상시 |
| **선점 정책** | 체크포인트 후 선점 | 긴급 작업 위해 학습 일시 중단 |
| **대기열** | Priority FIFO | 우선순위 내 FIFO |

### 7.3 GPU 모니터링 메트릭

| 메트릭 | 수집 주기 | 임계치 | 알림 |
|--------|----------|--------|------|
| **GPU Utilization** | 10초 | 90% 이상 5분 지속 | Warning |
| **GPU Memory Usage** | 10초 | 95% 이상 | Critical |
| **GPU Temperature** | 30초 | 85°C 이상 | Critical |
| **GPU Power** | 30초 | TDP 초과 | Warning |
| **vGPU Scheduler Latency** | 10초 | 100ms 이상 | Warning |

---

## 8. VM 템플릿 및 표준화

### 8.1 VM 템플릿 목록

| 템플릿 ID | OS | 스펙 | GPU | 용도 | 포함 패키지 |
|----------|-----|------|-----|------|------------|
| **TPL-WEB** | Ubuntu 22.04 | 2vCPU/4GB | - | 웹서버 | nginx, node_exporter |
| **TPL-APP** | Ubuntu 22.04 | 4vCPU/8GB | - | 애플리케이션 | python, docker, node_exporter |
| **TPL-DB** | Ubuntu 22.04 | 4vCPU/8GB | - | 데이터베이스 | postgresql-client, node_exporter |
| **TPL-MON** | Ubuntu 22.04 | 2vCPU/4GB | - | 모니터링 | prometheus, grafana |
| **TPL-AI-TRAIN** | Ubuntu 22.04 | 8vCPU/32GB | Passthrough | AI 학습 | CUDA, PyTorch, dcgm-exporter |
| **TPL-AI-INFER** | Ubuntu 22.04 | 4vCPU/16GB | vGPU (8GB) | AI 추론 | CUDA, TensorRT, dcgm-exporter |
| **TPL-AI-DEV** | Ubuntu 22.04 | 4vCPU/16GB | vGPU (8GB) | AI 개발 | CUDA, Jupyter, PyTorch |

### 8.2 AI VM 템플릿 구성 상세

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        AI VM 템플릿 구성                                     │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   TPL-AI-TRAIN (학습용):                                                    │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  - Ubuntu 22.04 LTS                                                 │  │
│   │  - NVIDIA Driver 535.x                                              │  │
│   │  - CUDA Toolkit 12.x                                                │  │
│   │  - cuDNN 8.x                                                        │  │
│   │  - PyTorch 2.x / TensorFlow 2.x                                     │  │
│   │  - Horovod (분산 학습)                                              │  │
│   │  - dcgm-exporter (GPU 메트릭)                                       │  │
│   │  - 대용량 로컬 NVMe (체크포인트용)                                  │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   TPL-AI-INFER (추론용):                                                    │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  - Ubuntu 22.04 LTS                                                 │  │
│   │  - NVIDIA Driver 535.x (vGPU Guest)                                 │  │
│   │  - CUDA Toolkit 12.x                                                │  │
│   │  - TensorRT (최적화 추론)                                           │  │
│   │  - Triton Inference Server                                          │  │
│   │  - dcgm-exporter (GPU 메트릭)                                       │  │
│   │  - 모델 캐시 볼륨 마운트                                            │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   Cloud-init 설정 (AI VM):                                                  │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  #cloud-config                                                      │  │
│   │  hostname: ${vm_name}                                               │  │
│   │  timezone: Asia/Seoul                                               │  │
│   │  mounts:                                                            │  │
│   │    - ["/dev/vdb", "/data/training", "ext4", "defaults", "0", "2"]   │  │
│   │  runcmd:                                                            │  │
│   │    - nvidia-smi                                                     │  │
│   │    - systemctl enable dcgm-exporter                                 │  │
│   │    - systemctl start dcgm-exporter                                  │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 8.3 VM 명명 규칙

```
{환경}-{테넌트/용도}-{역할}-{번호}

예시:
- dev-a-web-01      : 개발환경, 테넌트A, 웹서버, 1번
- dev-b-app-01      : 개발환경, 테넌트B, 앱서버, 1번
- dev-a-ai-01       : 개발환경, 테넌트A, AI VM, 1번
- dev-shared-train-01 : 개발환경, 공용, 학습서버, 1번
- dev-shared-infer-01 : 개발환경, 공용, 추론서버, 1번
- dev-mgmt-mon-01   : 개발환경, 관리, 모니터링, 1번
```

---

## 9. 검증 워크로드 배포 계획

### 9.1 검증 목적

> 인프라 설계의 정상 동작을 확인하기 위한 샘플 워크로드 배포

| 검증 항목 | 검증 방법 |
|----------|----------|
| **테넌트 격리** | 테넌트 간 네트워크/GPU 접근 불가 확인 |
| **리소스 쿼터** | 쿼터 초과 시 VM/GPU 생성 차단 확인 |
| **HA** | 호스트 장애 시 VM 자동 재시작 확인 |
| **Anti-Affinity** | VM이 다른 호스트에 분산되었는지 확인 |
| **GPU 할당** | vGPU 정상 할당 및 추론 동작 확인 |
| **GPU 스케줄링** | 작업 큐잉 및 Fair-Share 동작 확인 |

### 9.2 검증 환경 VM 구성

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                     검증 워크로드 배포 구성                                   │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   테넌트 A (A시청)           테넌트 B (B구청)           테넌트 C (C군청)    │
│   ┌─────────────────┐       ┌─────────────────┐       ┌─────────────────┐  │
│   │  dev-a-web-01   │       │  dev-b-web-01   │       │  dev-c-web-01   │  │
│   │  (2vCPU/4GB)    │       │  (2vCPU/4GB)    │       │  (2vCPU/4GB)    │  │
│   │  nginx + 샘플앱 │       │  nginx + 샘플앱 │       │  nginx + 샘플앱 │  │
│   ├─────────────────┤       ├─────────────────┤       └─────────────────┘  │
│   │  dev-a-app-01   │       │  dev-b-app-01   │                            │
│   │  (2vCPU/4GB)    │       │  (2vCPU/4GB)    │                            │
│   │  Python API     │       │  Python API     │                            │
│   ├─────────────────┤       ├─────────────────┤                            │
│   │  dev-a-ai-01    │       │  dev-b-ai-01    │                            │
│   │  (4vCPU/16GB)   │       │  (4vCPU/16GB)   │                            │
│   │  vGPU 8GB       │       │  vGPU 8GB       │                            │
│   │  테넌트 특화AI  │       │  테넌트 특화AI  │                            │
│   └─────────────────┘       └─────────────────┘                            │
│                                                                             │
│   공용 AI 플랫폼                                                            │
│   ┌─────────────────┐       ┌─────────────────┐       ┌─────────────────┐  │
│   │dev-shared-train │       │dev-shared-infer │       │dev-shared-model │  │
│   │ (8vCPU/32GB)    │       │ (4vCPU/16GB)    │       │ (2vCPU/8GB)     │  │
│   │ GPU Passthrough │       │ vGPU 8GB x 2    │       │ Model Registry  │  │
│   │ 공용 학습       │       │ 추론 서비스     │       │                 │  │
│   └─────────────────┘       └─────────────────┘       └─────────────────┘  │
│                                                                             │
│   관리/운영 영역                                                            │
│   ┌─────────────────┐       ┌─────────────────┐       ┌─────────────────┐  │
│   │ dev-mgmt-mon-01 │       │ dev-mgmt-db-01  │       │ dev-mgmt-gw-01  │  │
│   │ (2vCPU/4GB)     │       │ (4vCPU/8GB)     │       │ (2vCPU/4GB)     │  │
│   │ Prometheus      │       │ PostgreSQL      │       │ API Gateway     │  │
│   │ Grafana         │       │ (공용 DB)       │       │ Load Balancer   │  │
│   └─────────────────┘       └─────────────────┘       └─────────────────┘  │
│                                                                             │
│   총 VM: ~15대 (테넌트 7대 + 공용 AI 3대 + 관리 3대 + 기타)                │
│   총 GPU: 6개 (학습 Passthrough 2개 + 추론/테넌트 vGPU 4개)                │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 9.3 검증 시나리오

| 시나리오 | 절차 | 예상 결과 |
|----------|------|----------|
| **SC-01: 테넌트 격리** | 테넌트 A VM에서 테넌트 B VM ping | 연결 실패 (차단) |
| **SC-02: 쿼터 테스트** | 테넌트 A에서 쿼터 초과 VM 생성 시도 | 생성 실패 |
| **SC-03: HA 테스트** | 호스트 장애 시뮬레이션 | VM 자동 재시작 |
| **SC-04: Anti-Affinity** | 동일 서비스 VM 배치 확인 | 다른 호스트에 분산 |
| **SC-05: GPU 할당** | 테넌트 AI VM에서 vGPU 확인 | nvidia-smi 정상 출력 |
| **SC-06: GPU 격리** | 테넌트 A GPU에서 테넌트 B 메모리 접근 | 접근 불가 |
| **SC-07: GPU 스케줄링** | 동시 GPU 작업 제출 | Fair-Share 배분 |
| **SC-08: AI 추론 테스트** | 추론 API 호출 | 정상 응답 |

### 9.4 샘플 AI 워크로드

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        샘플 AI 워크로드                                      │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   1. 샘플 학습 워크로드                                                     │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  - MNIST 분류 모델 (로컬 학습)                                      │  │
│   │  - 학습 시간: ~30분                                                 │  │
│   │  - 체크포인트 저장 테스트                                           │  │
│   │  - 분산 학습 데모 (2 GPU)                                           │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   2. 샘플 추론 워크로드                                                     │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  - 사전 학습된 이미지 분류 모델 (ResNet-50)                         │  │
│   │  - REST API 엔드포인트 제공                                         │  │
│   │  - 초당 요청 처리량 측정                                            │  │
│   │  - 지연 시간 측정 (<100ms 목표)                                     │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│   3. 테넌트 특화 모델 (데모)                                                │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  - 테넌트 A: 민원 분류 모델 (텍스트)                                │  │
│   │  - 테넌트 B: 문서 OCR 모델 (이미지)                                 │  │
│   │  - 각 테넌트 vGPU에서 독립 실행                                     │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 변경 이력

| 버전 | 날짜 | 변경 내용 | 작성자 |
|------|------|----------|--------|
| 1.0 | 2026-01-30 | 초안 작성 | - |
| 2.0 | 2026-02-02 | **GPU 가상화 통합**: GPU 설계, vGPU 프로파일, GPU 스케줄링, AI VM 템플릿 추가 | - |

---

## 관련 문서

- [01_프로젝트_개요서.md](01_프로젝트_개요서.md)
- [02_팀_역할분담.md](02_팀_역할분담.md)
- [03_상세설계_가이드.md](03_상세설계_가이드.md)
- [05_네트워크_보안_설계서.md](05_네트워크_보안_설계서.md)
- [06_스토리지_설계서.md](06_스토리지_설계서.md)
