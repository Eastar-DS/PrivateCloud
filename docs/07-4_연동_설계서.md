# 외부 시스템 연동 설계서

## 공공기관 AI 공동 활용 인프라 구축 프로젝트
### AI 기반 문서 태깅 시스템을 위한 멀티 테넌트 프라이빗 클라우드 설계

| 항목 | 내용 |
|------|------|
| 문서명 | 외부 시스템 연동 설계서 |
| 버전 | 1.0 |
| 작성일 | 2026-02-09 |
| 프로젝트명 | 공공기관 AI 공동 활용 인프라 구축 |
| 상위 문서 | 07_백엔드_설계서.md |

---

**목차**

1. [연동 시스템 개요](#1-연동-시스템-개요)
2. [RabbitMQ 비동기 처리 설계](#2-rabbitmq-비동기-처리-설계)
3. [Ceph RGW (S3) 스토리지 연동](#3-ceph-rgw-s3-스토리지-연동)
4. [AI Worker 연동](#4-ai-worker-연동)
5. [연동 장애 처리](#5-연동-장애-처리)

---

## 1. 연동 시스템 개요

### 1.1 목적

본 문서는 SmartDocs 백엔드 애플리케이션이 연동하는 외부 시스템의 프로토콜, 메시지 규격, 설정 및 장애 대응 전략을 정의한다. Spring Boot 애플리케이션을 중심으로 MariaDB, RabbitMQ, Ceph RGW, AI Worker 간의 통신 설계를 포함한다.

### 1.2 연동 시스템 목록

| 시스템 | 용도 | 프로토콜 | 위치 |
|--------|------|---------|------|
| MariaDB Primary | 메타데이터 쓰기 | JDBC (3306) | VLAN 50 |
| MariaDB Replica | 메타데이터 읽기 | JDBC (3306) | VLAN 50 |
| RabbitMQ | 비동기 태깅 작업 | AMQP (5672) | VLAN 40 (App서버) |
| Ceph RGW | 문서 파일 저장 | S3 API (7480) | VLAN 60 |
| AI Worker | 태깅 결과 콜백 | HTTP (8080) | VLAN 50 |

### 1.3 연동 구조 전체 개요

```
┌──────────────────────────────────────────────────────────────────┐
│                    연동 시스템 전체 구조                            │
├──────────────────────────────────────────────────────────────────┤
│                                                                  │
│   [사용자 / 기관 내부망]                                          │
│        │                                                         │
│        │ HTTPS (443)                                             │
│        ▼                                                         │
│   ┌──────────┐     ┌──────────────┐     ┌──────────────┐        │
│   │  Nginx   │ ──> │ Spring Boot  │ ──> │  RabbitMQ    │        │
│   │ (VLAN 40)│     │  (VLAN 40)   │     │  (VLAN 40)   │        │
│   └──────────┘     └──────┬───────┘     └──────┬───────┘        │
│                           │                     │                │
│              ┌────────────┼─────────────────────┘                │
│              │            │                                      │
│              ▼            ▼                                      │
│   ┌──────────────┐  ┌──────────────┐  ┌──────────────┐         │
│   │ MariaDB      │  │ Ceph RGW     │  │ AI Worker    │         │
│   │ Pri/Rep      │  │ (S3 API)     │  │ (Python/     │         │
│   │ (VLAN 50)    │  │ (VLAN 60)    │  │  Docker)     │         │
│   └──────────────┘  └──────────────┘  │ (VLAN 50)    │         │
│                                        └──────────────┘         │
│                                                                  │
└──────────────────────────────────────────────────────────────────┘
```

### 1.4 MariaDB 연동 개요

Spring Boot 애플리케이션은 MariaDB Primary/Replica 이중화 구성을 통해 읽기/쓰기를 분리한다.

| 항목 | Primary | Replica |
|------|---------|---------|
| 호스트 | dev-data-db-pri (VLAN 50) | dev-data-db-rep (VLAN 50) |
| 포트 | 3306 | 3306 |
| 용도 | INSERT, UPDATE, DELETE | SELECT (읽기 분산) |
| 연결 풀 | HikariCP (max 20) | HikariCP (max 20) |
| Failover | Replica 승격 (수동/자동) | Primary로 폴백 |

Spring 데이터소스 설정:

```yaml
spring:
  datasource:
    primary:
      url: jdbc:mariadb://dev-data-db-pri:3306/smartdocs
      username: ${DB_USER}
      password: ${DB_PASS}
      hikari:
        maximum-pool-size: 20
        connection-timeout: 5000
        validation-timeout: 3000
    replica:
      url: jdbc:mariadb://dev-data-db-rep:3306/smartdocs
      username: ${DB_READONLY_USER}
      password: ${DB_READONLY_PASS}
      hikari:
        maximum-pool-size: 20
        connection-timeout: 5000
        read-only: true
```

---

## 2. RabbitMQ 비동기 처리 설계

### 2.1 비동기 처리 흐름

문서 업로드 후 AI 태깅 작업은 비동기로 처리된다. Spring Boot 애플리케이션이 RabbitMQ에 메시지를 발행하면, AI Worker가 소비하여 태깅 추론을 수행하고 콜백 API를 통해 결과를 반환한다.

```
[사용자] --> [Nginx] --> [Spring Boot]
                              │
                        1. 문서 Ceph S3 저장
                        2. DB 레코드 삽입 (PENDING)
                        3. RabbitMQ 메시지 발행
                              │
                        [RabbitMQ (App서버)]
                        Exchange: document.exchange (topic)
                              │
                        Queue: tagging.queue (durable)
                              │
                        [AI Worker (Python/Docker)]
                              │
                        4. Ceph S3에서 문서 다운로드
                        5. KoBERT 추론 + OCR
                        6. 콜백 API 호출
                              │
                        [Spring Boot /internal/v1/tagging/callback]
                        7. tags 테이블 INSERT
                        8. tagging_jobs.status = COMPLETED
```

### 2.2 RabbitMQ 구성 설정

| 항목 | 설정 |
|------|------|
| Exchange | document.exchange (topic) |
| Queue | tagging.queue (durable) |
| Routing Key | document.tagging.request |
| DLX | document.dlx |
| DLQ | tagging.dlq |
| Retry | 3회, exponential backoff (1s, 5s, 30s) |
| Message TTL | 1시간 |
| Prefetch | 1 |

### 2.3 메시지 규격

#### 태깅 요청 메시지 (Publisher -> Queue)

```json
{
  "job_id": "uuid",
  "document_id": "uuid",
  "tenant_id": "dept-a",
  "storage_key": "documents-dept-a/2026/02/09/uuid/1/report.pdf",
  "file_name": "report.pdf",
  "mime_type": "application/pdf",
  "requested_at": "2026-02-09T10:30:00Z",
  "callback_url": "http://dev-svc-app-01:8080/internal/v1/tagging/callback"
}
```

| 필드 | 타입 | 설명 |
|------|------|------|
| job_id | UUID | 태깅 작업 고유 식별자 |
| document_id | UUID | 문서 고유 식별자 |
| tenant_id | String | 테넌트(부서) 식별자 |
| storage_key | String | Ceph S3 오브젝트 키 |
| file_name | String | 원본 파일명 |
| mime_type | String | 파일 MIME 타입 |
| requested_at | ISO 8601 | 요청 시각 |
| callback_url | URL | 결과 수신 엔드포인트 |

#### 콜백 응답 메시지 (AI Worker -> Spring Boot)

```json
{
  "job_id": "uuid",
  "status": "COMPLETED",
  "tags": [
    { "name": "행정", "confidence": 0.95 },
    { "name": "계약서", "confidence": 0.87 }
  ],
  "model_version": "v1.2.0",
  "processed_at": "2026-02-09T10:30:05Z"
}
```

| 필드 | 타입 | 설명 |
|------|------|------|
| job_id | UUID | 태깅 작업 고유 식별자 |
| status | Enum | COMPLETED, FAILED |
| tags | Array | 추출된 태그 목록 (이름 + 신뢰도) |
| model_version | String | 사용된 모델 버전 |
| processed_at | ISO 8601 | 처리 완료 시각 |

실패 시 콜백:

```json
{
  "job_id": "uuid",
  "status": "FAILED",
  "error_code": "MODEL_INFERENCE_ERROR",
  "error_message": "KoBERT inference timeout after 30s",
  "model_version": "v1.2.0",
  "processed_at": "2026-02-09T10:30:35Z"
}
```

### 2.4 실패 처리 설계

```
┌──────────────────────────────────────────────────────────────────┐
│                    실패 처리 흐름                                   │
├──────────────────────────────────────────────────────────────────┤
│                                                                  │
│   [tagging.queue]                                                │
│        │                                                         │
│        │ 소비 실패 (예외 발생)                                    │
│        ▼                                                         │
│   [재시도 1회차] -- 1초 대기 --> [재시도 2회차] -- 5초 대기 -->   │
│                                                                  │
│   [재시도 3회차] -- 30초 대기 --> [실패 확정]                     │
│                                         │                        │
│                                         ▼                        │
│                                   [tagging.dlq]                  │
│                                         │                        │
│                                         ▼                        │
│                              DLQ Consumer 처리:                  │
│                              1. tagging_jobs.status = FAILED     │
│                              2. 에러 로그 기록                    │
│                              3. 관리자 알림 (선택)                │
│                                                                  │
│   수동 재처리:                                                    │
│   POST /v1/documents/{id}/retag                                  │
│   -> 새 tagging_job 생성 -> RabbitMQ 재발행                      │
│                                                                  │
└──────────────────────────────────────────────────────────────────┘
```

실패 처리 정책:

- RabbitMQ 소비 측에서 예외 발생 시 최대 3회 재시도 (exponential backoff: 1s, 5s, 30s)
- 3회 재시도 후에도 실패하면 DLQ(tagging.dlq)로 이동
- DLQ Consumer가 해당 작업의 상태를 FAILED로 갱신하고 에러 로그를 기록
- 수동 재태깅: `POST /v1/documents/{id}/retag` API를 통해 새로운 작업을 생성하여 재처리

### 2.5 OCR 큐 설계 (설계만 포함, 구현 범위 외)

향후 이미지 기반 문서에 대한 OCR 전처리가 필요할 경우를 대비한 큐 설계이다.

| 항목 | 설정 |
|------|------|
| Queue | ocr.queue (durable) |
| Routing Key | document.ocr.request |
| 트리거 조건 | MIME 타입이 image/* 인 경우 |
| 처리 흐름 | OCR 추출 완료 후 tagging.queue로 재발행 |

OCR 큐 처리 흐름 (향후 구현):

```
[문서 업로드 (image/*)]
      │
      ▼
[ocr.queue] --> [AI Worker: OCR 처리]
                      │
                      ▼
               텍스트 추출 완료
                      │
                      ▼
              [tagging.queue] --> [AI Worker: KoBERT 추론]
```

### 2.6 Spring RabbitMQ 설정

```yaml
spring:
  rabbitmq:
    host: dev-svc-app-01
    port: 5672
    username: ${RABBITMQ_USER}
    password: ${RABBITMQ_PASS}
    virtual-host: /smartdocs
    listener:
      simple:
        prefetch: 1
        retry:
          enabled: true
          max-attempts: 3
          initial-interval: 1000
          multiplier: 5
          max-interval: 30000
```

RabbitMQ Exchange/Queue 선언 설정:

```yaml
# application.yml 내 커스텀 프로퍼티
messaging:
  exchange:
    name: document.exchange
    type: topic
  queues:
    tagging:
      name: tagging.queue
      routing-key: document.tagging.request
      durable: true
      dlx: document.dlx
      dlq: tagging.dlq
      message-ttl: 3600000
    ocr:
      name: ocr.queue
      routing-key: document.ocr.request
      durable: true
```

---

## 3. Ceph RGW (S3) 스토리지 연동

### 3.1 버킷 구조

| 버킷 | 용도 | 접근 주체 |
|------|------|----------|
| smartdocs-dept-a | 부서 A 문서 | App Server, AI Worker |
| smartdocs-dept-b | 부서 B 문서 | App Server, AI Worker |
| smartdocs-dept-c | 부서 C 문서 | App Server, AI Worker |
| smartdocs-models | KoBERT 모델 | AI Worker, Train Worker |
| smartdocs-results | 태깅 상세 결과 | AI Worker (write), App (read) |

### 3.2 오브젝트 키 네이밍 규칙

```
smartdocs-{tenant}/{year}/{month}/{day}/{document_id}/{version}/{filename}
```

예시:

```
smartdocs-dept-a/2026/02/09/550e8400-e29b-41d4-a716-446655440000/1/report.pdf
smartdocs-dept-b/2026/02/09/6ba7b810-9dad-11d1-80b4-00c04fd430c8/1/contract.docx
smartdocs-results/dept-a/550e8400.../result.json
smartdocs-models/kobert/v1.2.0/model.pt
```

키 구조 설명:

| 세그먼트 | 설명 | 예시 |
|----------|------|------|
| tenant | 테넌트(부서) 식별자 | dept-a |
| year/month/day | 업로드 날짜 기반 파티셔닝 | 2026/02/09 |
| document_id | 문서 UUID | 550e8400... |
| version | 문서 버전 번호 | 1 |
| filename | 원본 파일명 | report.pdf |

### 3.3 업로드 프로세스

```
┌──────────────────────────────────────────────────────────────────┐
│                    문서 업로드 흐름                                 │
├──────────────────────────────────────────────────────────────────┤
│                                                                  │
│   1. Multipart 파일 수신                                         │
│      │                                                           │
│   2. Stream 기반 SHA-256 해시 계산                                │
│      │                                                           │
│   3. 테넌트 쿼터 확인                                             │
│      │  tenants.used_bytes + file_size <= quota_bytes ?           │
│      │  ├── NO  --> 413 Payload Too Large 응답                   │
│      │  └── YES --> 계속 진행                                     │
│      │                                                           │
│   4. Ceph RGW 업로드 (PutObjectRequest)                          │
│      │  storage_key = smartdocs-{tenant}/{date}/{doc_id}/...     │
│      │                                                           │
│   5. documents 테이블에 레코드 삽입                               │
│      │  storage_key, sha256_hash, file_size 저장                 │
│      │                                                           │
│   6. tenants.used_bytes 갱신 (+file_size)                        │
│      │                                                           │
│   7. RabbitMQ 태깅 요청 메시지 발행                               │
│                                                                  │
└──────────────────────────────────────────────────────────────────┘
```

### 3.4 다운로드 프로세스

두 가지 방식을 지원하며, 운영 환경에 따라 선택한다.

**Option A: Pre-signed URL (권장)**

- Ceph RGW에서 직접 다운로드하는 서명된 URL 생성
- 만료 시간: 30분
- 서버 부하 최소화, 대용량 파일에 적합

**Option B: Proxy Streaming**

- Spring Boot가 Ceph에서 읽어 클라이언트에 스트리밍 전달
- 감사 로깅이 필요한 경우 사용
- 파일 접근 기록을 정확히 남길 수 있음

### 3.5 파일 무결성 검증 (NFR-10)

업로드 시 SHA-256 해시를 계산하여 저장하고, 다운로드 시 재계산하여 무결성을 검증한다.

```java
// 업로드 시 해시 계산
MessageDigest digest = MessageDigest.getInstance("SHA-256");
try (DigestInputStream dis = new DigestInputStream(inputStream, digest)) {
    // S3에 스트리밍 업로드
    s3Client.putObject(putRequest, RequestBody.fromInputStream(dis, contentLength));
}
String hash = HexFormat.of().formatHex(digest.digest());
document.setSha256Hash(hash);

// 다운로드 시 무결성 검증
String storedHash = document.getSha256Hash();
String downloadedHash = DigestUtils.sha256Hex(downloadedInputStream);
if (!storedHash.equals(downloadedHash)) {
    throw new DataIntegrityException("파일 무결성 검증 실패: " + document.getId());
}
```

### 3.6 지원 파일 형식

| 분류 | 확장자 |
|------|--------|
| 문서 | pdf, docx, doc, xlsx, xls, pptx, ppt, txt, rtf, hwp |
| 이미지 | jpg, jpeg, png, tiff, bmp |
| 압축 | zip (자동 해제 후 개별 처리) |

MIME 타입 검증은 파일 확장자와 매직 바이트(Magic Bytes) 이중 검사로 수행한다. 허용되지 않은 파일 형식은 업로드 단계에서 `415 Unsupported Media Type`으로 거부한다.

### 3.7 Spring S3 클라이언트 설정

```yaml
storage:
  s3:
    endpoint: http://10.0.60.40:7480
    access-key: ${S3_ACCESS_KEY}
    secret-key: ${S3_SECRET_KEY}
    region: default
    max-file-size: 100MB
    presigned-url-expiry: 30m
    bucket-prefix: smartdocs
```

S3 클라이언트 Bean 설정 예시:

```java
@Configuration
public class S3Config {

    @Value("${storage.s3.endpoint}")
    private String endpoint;

    @Value("${storage.s3.access-key}")
    private String accessKey;

    @Value("${storage.s3.secret-key}")
    private String secretKey;

    @Value("${storage.s3.region}")
    private String region;

    @Bean
    public S3Client s3Client() {
        return S3Client.builder()
            .endpointOverride(URI.create(endpoint))
            .region(Region.of(region))
            .credentialsProvider(StaticCredentialsProvider.create(
                AwsBasicCredentials.create(accessKey, secretKey)))
            .serviceConfiguration(S3Configuration.builder()
                .pathStyleAccessEnabled(true)
                .build())
            .build();
    }

    @Bean
    public S3Presigner s3Presigner() {
        return S3Presigner.builder()
            .endpointOverride(URI.create(endpoint))
            .region(Region.of(region))
            .credentialsProvider(StaticCredentialsProvider.create(
                AwsBasicCredentials.create(accessKey, secretKey)))
            .build();
    }
}
```

---

## 4. AI Worker 연동

### 4.1 AI Worker 개요

| 항목 | 내용 |
|------|------|
| 호스트 | dev-ai-worker-01 (단일 VM, 2개 프로세스) |
| 위치 | VLAN 50 (데이터망) |
| 런타임 | Python 3.10+ / Docker |
| 모델 | KoBERT (CPU 추론) |

**2개 프로세스 아키텍처** — 같은 VM에서 역할별로 프로세스를 분리하여 독립 개발/배포한다.

| 프로세스 | 역할 | 개발 담당 | 기술 스택 |
|----------|------|-----------|-----------|
| **pika Consumer (워커 노드)** | RabbitMQ 메시지 수신, S3 문서 다운로드, 태깅 API 호출, Spring Boot 콜백 전송 | 백엔드 개발자 | pika, boto3, requests |
| **FastAPI 태깅 서비스** | KoBERT 모델 로딩/추론, `POST localhost:8000/predict` 엔드포인트 | AI 담당자 | FastAPI, torch, transformers |

> **분리 이유**: 백엔드 개발자와 AI 담당자의 역할을 명확히 구분하되, 별도 VM을 추가하지 않고 localhost 통신으로 네트워크 지연 없이 연동한다.

### 4.2 통신 구조

```
┌──────────────────────────────────────────────────────────────────┐
│                    AI Worker 연동 구조                              │
├──────────────────────────────────────────────────────────────────┤
│                                                                  │
│   [Spring Boot (VLAN 40)]                                        │
│        │                                                         │
│        │ 1. AMQP 메시지 발행 (document.tagging.request)          │
│        ▼                                                         │
│   [RabbitMQ (VLAN 40)]                                           │
│        │                                                         │
│        │ 2. AMQP 메시지 소비 (tagging.queue)                     │
│        ▼                                                         │
│   [dev-ai-worker-01 (VLAN 50)]                                   │
│   ┌──────────────────────────────────────────────────────────┐   │
│   │  [pika Consumer - 워커 노드] (백엔드 개발자)              │   │
│   │        │                                                  │   │
│   │        │ 3. Ceph S3에서 문서 다운로드 (VLAN 60)           │   │
│   │        │ 4. localhost:8000/predict 호출                    │   │
│   │        │         │                                        │   │
│   │        │         ▼                                        │   │
│   │        │  [FastAPI 태깅 서비스] (AI 담당자)                │   │
│   │        │   - KoBERT CPU 추론 수행                         │   │
│   │        │   - (필요 시) OCR 텍스트 추출                    │   │
│   │        │   - 태그 + 신뢰도 반환                           │   │
│   │        │                                                  │   │
│   │        │ 5. HTTP POST 콜백 (결과 반환)                    │   │
│   └────────┼──────────────────────────────────────────────────┘   │
│            ▼                                                      │
│   [Spring Boot /internal/v1/tagging/callback]                    │
│        │                                                         │
│        │ 6. tags 테이블 INSERT                                    │
│        │ 7. tagging_jobs.status 갱신                              │
│                                                                  │
└──────────────────────────────────────────────────────────────────┘
```

### 4.3 콜백 엔드포인트

| 항목 | 내용 |
|------|------|
| 엔드포인트 | `POST /internal/v1/tagging/callback` |
| 네트워크 노출 | Nginx를 통해 외부 노출하지 않음 (내부 VLAN 전용) |
| 인증 | 내부 서비스 간 통신 (VLAN 격리로 보호) |
| 타임아웃 | 콜백 응답 30초 |
| Content-Type | application/json |

콜백 수신 후 처리 로직:

1. job_id로 tagging_jobs 레코드 조회
2. status 검증 (PENDING 상태인 경우만 처리)
3. status == COMPLETED: tags 테이블에 태그 INSERT, tagging_jobs.status = COMPLETED
4. status == FAILED: tagging_jobs.status = FAILED, error 정보 기록

### 4.4 AI Worker 처리 사양

| 항목 | 사양 |
|------|------|
| 모델 | KoBERT (monologg/kobert) |
| 추론 방식 | CPU 기반 (GPU 미사용) |
| 문서당 처리 시간 | 5초 이내 (목표) |
| 일 평균 처리량 | 150건 |
| 동시 처리 | 1건 (Prefetch 1) |
| 모델 로딩 | 서비스 시작 시 Ceph S3에서 로드 후 메모리 상주 |

### 4.5 AI Worker Python 의존성

**pika Consumer (워커 노드) — 백엔드 개발자**

| 패키지 | 용도 |
|--------|------|
| `pika` | RabbitMQ 메시지 소비 (Consumer) |
| `boto3` | Ceph S3 문서 다운로드 |
| `requests` | FastAPI 태깅 서비스 호출 (localhost) + Spring Boot 콜백 전송 |

**FastAPI 태깅 서비스 — AI 담당자**

| 패키지 | 용도 |
|--------|------|
| `fastapi` | HTTP API 서버 (`POST /predict`) |
| `uvicorn` | ASGI 서버 |
| `torch` | KoBERT 모델 추론 (PyTorch CPU) |
| `transformers` | KoBERT 토크나이저/모델 로딩 |

---

## 5. 연동 장애 처리

### 5.1 장애 시나리오별 대응 전략

| 장애 대상 | 영향 | 대응 |
|-----------|------|------|
| MariaDB Primary | 쓰기 불가 | Replica 승격 (수동/자동) |
| MariaDB Replica | 읽기 부하 집중 | Primary로 폴백 |
| RabbitMQ | 태깅 요청 불가 | 503 반환, 재시도 안내 |
| Ceph RGW | 파일 업로드/다운로드 불가 | 503 반환 |
| AI Worker | 태깅 처리 지연 | DLQ 적재, 복구 후 재처리 |

### 5.2 장애 상세 대응 절차

#### MariaDB Primary 장애

```
[장애 감지] 하트비트 타임아웃 (30초)
     │
     ▼
[App 서버] 쓰기 요청 실패 -> 503 Service Unavailable 반환
     │
     ▼
[복구 절차]
  1. Replica를 Primary로 승격
  2. App 서버 데이터소스 연결 변경 (또는 VIP 이동)
  3. 기존 Primary 복구 후 Replica로 재구성
  4. 정상 확인 후 서비스 복원
```

#### MariaDB Replica 장애

```
[장애 감지] 연결 실패
     │
     ▼
[App 서버] 읽기 요청을 Primary로 폴백 (자동)
     │
     ▼
[복구 절차]
  1. Replica 서버 상태 확인 및 복구
  2. Replication 동기화 재설정
  3. Replica 정상 확인 후 읽기 트래픽 복원
```

#### RabbitMQ 장애

```
[장애 감지] AMQP 연결 실패
     │
     ▼
[App 서버]
  - 문서 업로드: 성공 (Ceph + DB 저장까지 완료)
  - 태깅 요청: 실패 -> tagging_jobs.status = PENDING 유지
  - 사용자 응답: 202 Accepted + "태깅 처리가 지연되고 있습니다"
     │
     ▼
[복구 후]
  - RabbitMQ 복구 시 PENDING 상태의 작업을 배치로 재발행
  - 스케줄러: 10분 간격으로 PENDING 상태 작업 확인 및 재발행
```

#### Ceph RGW 장애

```
[장애 감지] S3 API 응답 실패
     │
     ▼
[App 서버]
  - 업로드 요청: 503 Service Unavailable
  - 다운로드 요청: 503 Service Unavailable
  - 태깅 요청: 큐에 적재되나 AI Worker가 파일 접근 불가 -> DLQ로 이동
     │
     ▼
[복구 절차]
  1. Ceph 클러스터 상태 확인 (ceph status)
  2. RGW 데몬 재시작
  3. DLQ에 적재된 작업 재처리
```

#### AI Worker 장애

```
[장애 감지] 콜백 미수신 (타임아웃)
     │
     ▼
[RabbitMQ]
  - 메시지 소비 후 ACK 미전송 -> 재큐잉
  - 3회 재시도 후 DLQ 적재
     │
     ▼
[복구 절차]
  1. AI Worker Docker 컨테이너 상태 확인
  2. 컨테이너 재시작 또는 호스트 VM 확인
  3. DLQ 메시지 재처리 (수동 또는 자동)
```

### 5.3 헬스체크 설정

각 연동 시스템에 대한 헬스체크를 Spring Boot Actuator를 통해 노출한다.

```yaml
management:
  endpoint:
    health:
      show-details: always
  health:
    db:
      enabled: true
    rabbit:
      enabled: true
    # 커스텀 헬스 인디케이터
    s3:
      enabled: true
```

헬스체크 응답 예시:

```json
{
  "status": "UP",
  "components": {
    "db-primary": { "status": "UP" },
    "db-replica": { "status": "UP" },
    "rabbit": { "status": "UP" },
    "s3": { "status": "UP" }
  }
}
```

### 5.4 서킷브레이커 설정

외부 시스템 장애가 애플리케이션 전체에 전파되지 않도록 서킷브레이커를 적용한다.

| 대상 | 실패 임계치 | 열림 유지 시간 | 반열림 허용 호출 |
|------|-----------|-------------|---------------|
| MariaDB Primary | 연속 5회 실패 | 30초 | 3회 |
| MariaDB Replica | 연속 5회 실패 | 30초 | 3회 |
| Ceph RGW | 연속 3회 실패 | 60초 | 2회 |
| AI Worker 콜백 | N/A (비동기) | N/A | N/A |

---

## 변경 이력

| 버전 | 날짜 | 변경 내용 | 작성자 |
|------|------|----------|--------|
| 1.0 | 2026-02-09 | 초안 작성: RabbitMQ 비동기 설계, Ceph S3 연동, AI Worker 콜백, 장애 처리 | - |

---

## 관련 문서

- [07_백엔드_설계서.md](07_백엔드_설계서.md) - 백엔드 설계서 (상위 문서)
- [04_컴퓨트_설계서.md](04_컴퓨트_설계서.md) - 컴퓨트 설계서
- [05_네트워크_보안_설계서.md](05_네트워크_보안_설계서.md) - 네트워크/보안 설계서
- [06_스토리지_설계서.md](06_스토리지_설계서.md) - 스토리지 설계서
- [00_요구사항_명세서.md](00_요구사항_명세서.md) - 요구사항 명세서
