# 연동 설계서

## 공공기관 AI 공동 활용 인프라 구축 프로젝트
### AI 기반 문서 태깅 시스템을 위한 멀티 테넌트 프라이빗 클라우드 설계

| 항목 | 내용 |
|------|------|
| 문서명 | 연동 설계서 |
| 버전 | 2.0 |
| 작성일 | 2026-02-10 |
| 프로젝트명 | 공공기관 AI 공동 활용 인프라 구축 |
| 상위 문서 | 07_백엔드_설계서.md |

---

**목차**

1. [연동 시스템 개요](#1-연동-시스템-개요)
2. [RabbitMQ 비동기 처리](#2-rabbitmq-비동기-처리)
3. [AI 서버 HTTP API 연동](#3-ai-서버-http-api-연동)
4. [NFS 파일 스토리지 연동](#4-nfs-파일-스토리지-연동)
5. [전체 처리 흐름](#5-전체-처리-흐름)
6. [장애 처리 및 복구](#6-장애-처리-및-복구)

---

## 1. 연동 시스템 개요

### 1.1 연동 대상 시스템

| 시스템 | 연동 방식 | 위치 | 설명 |
|--------|----------|------|------|
| **RabbitMQ** | AMQP (localhost) | VLAN 20 (백엔드망) | App 서버 내장, 비동기 메시지 큐 |
| **AI 서버 (OCR)** | HTTP REST | VLAN 30 (AI망) :8001 | OCR 텍스트 추출 (FastAPI) |
| **AI 서버 (태깅)** | HTTP REST | VLAN 30 (AI망) :8000 | KoBERT 기반 문서 분류/태깅 (FastAPI) |
| **NFS (공유 파일시스템)** | NFS mount | VLAN 50 (스토리지망) | 문서 원본 파일 저장 |
| **MariaDB** | JDBC | VLAN 40 (DB망) :3306 | 문서 메타데이터, 태그 저장 |

### 1.2 아키텍처 개요

```
┌─────────────────────────────────────────────────────────────────────────┐
│                        App 서버 (VLAN 20)                                │
│                                                                         │
│  ┌──────────────┐     ┌──────────────┐     ┌──────────────────────┐    │
│  │  REST API    │────►│  RabbitMQ    │────►│ Spring AMQP Consumer │    │
│  │  Controller  │     │  (localhost) │     │  (@RabbitListener)   │    │
│  └──────────────┘     └──────────────┘     └──────────┬───────────┘    │
│         │                                              │                │
│         │ DB 저장 (PENDING)                            │ HTTP 호출      │
│         ▼                                              ▼                │
│  ┌──────────────┐                              ┌──────────────┐        │
│  │   MariaDB    │◄─── DB 결과 저장 ────────────│  OcrClient   │        │
│  │  (VLAN 40)   │     (COMPLETED/FAILED)       │ TaggingClient│        │
│  └──────────────┘                              └──────┬───────┘        │
│         │                                              │                │
│  ┌──────────────┐                              ┌──────▼───────┐        │
│  │   NFS        │◄─── 결과 저장 ───────────────│  AI 서버     │        │
│  │  (VLAN 50)   │                              │  (VLAN 30)   │        │
│  └──────────────┘                              │ :8001 OCR    │        │
│                                                 │ :8000 태깅   │        │
│                                                 └──────────────┘        │
└─────────────────────────────────────────────────────────────────────────┘
```

### 1.3 핵심 설계 원칙

| 원칙 | 설명 |
|------|------|
| **AI 서버 Stateless** | AI 서버는 DB/큐에 직접 접근하지 않음. HTTP 요청만 처리하는 순수 추론 서버 |
| **단일 소비자** | Spring AMQP Consumer가 메시지 소비, AI 호출, 결과 저장을 모두 담당 |
| **콜백 불필요** | Consumer가 동기적으로 AI 서버를 호출하고 직접 DB/NFS에 저장하므로 콜백 API 불필요 |
| **NFS 경로 전달** | AI 서버에 파일을 직접 전송하지 않고, NFS 파일 경로를 전달하여 AI 서버가 직접 읽기 |

---

## 2. RabbitMQ 비동기 처리

### 2.1 RabbitMQ 구성

| 항목 | 설정 |
|------|------|
| **위치** | App 서버 내장 (VLAN 20, localhost:5672) |
| **Exchange** | `document.exchange` (Direct) |
| **Queue** | `tagging.queue` |
| **Routing Key** | `tagging.request` |
| **DLQ** | `tagging.dlq` (Dead Letter Queue) |
| **메시지 형식** | JSON |
| **확인 모드** | Manual ACK |

### 2.2 Exchange / Queue 토폴로지

```
┌─────────────────────────────────────────────────────────────┐
│                       RabbitMQ (localhost)                    │
│                                                               │
│  ┌─────────────────────┐     ┌─────────────────────────┐    │
│  │  document.exchange   │────►│     tagging.queue       │    │
│  │  (Direct Exchange)   │     │  routing: tagging.request│    │
│  └─────────────────────┘     │  x-dead-letter-exchange: │    │
│                               │    dlx.exchange           │    │
│                               │  x-dead-letter-routing:   │    │
│                               │    tagging.dead           │    │
│                               └─────────────────────────┘    │
│                                                               │
│  ┌─────────────────────┐     ┌─────────────────────────┐    │
│  │   dlx.exchange      │────►│     tagging.dlq         │    │
│  │  (Direct Exchange)   │     │  routing: tagging.dead   │    │
│  └─────────────────────┘     └─────────────────────────┘    │
│                                                               │
└─────────────────────────────────────────────────────────────┘
```

### 2.3 메시지 형식

#### 태깅 요청 메시지

```json
{
  "jobId": "550e8400-e29b-41d4-a716-446655440000",
  "documentId": "7c9e6679-7425-40de-944b-e07fc1f90ae7",
  "tenantId": "dept-a",
  "documentType": "pdf",
  "storageKey": "dept-a/2026/02/10/7c9e6679.pdf",
  "contentText": null,
  "requestId": "req-abc-123",
  "createdAt": "2026-02-10T10:30:00Z"
}
```

#### 메시지 필드 설명

| 필드 | 타입 | 필수 | 설명 |
|------|------|------|------|
| jobId | String (UUID) | O | 태깅 작업 식별자 |
| documentId | String (UUID) | O | 문서 식별자 |
| tenantId | String | O | 테넌트(부서) ID |
| documentType | String | O | 문서 유형 (`text`, `pdf`, `txt`, `docx`, `hwp`) |
| storageKey | String | O | NFS 파일 상대 경로 |
| contentText | String | X | 텍스트 작성 시 원문 (documentType=text인 경우) |
| requestId | String (UUID) | O | 요청 추적 ID |
| createdAt | String (ISO 8601) | O | 메시지 생성 시각 |

### 2.4 Producer (메시지 발행)

```java
@Component
@Slf4j
public class TaggingMessageProducer {

    private final RabbitTemplate rabbitTemplate;

    private static final String EXCHANGE = "document.exchange";
    private static final String ROUTING_KEY = "tagging.request";

    public TaggingMessageProducer(RabbitTemplate rabbitTemplate) {
        this.rabbitTemplate = rabbitTemplate;
    }

    /** 태깅 요청 메시지를 RabbitMQ에 발행한다. */
    public void sendTaggingRequest(TaggingMessage message) {
        rabbitTemplate.convertAndSend(EXCHANGE, ROUTING_KEY, message, msg -> {
            msg.getMessageProperties().setContentType("application/json");
            msg.getMessageProperties().setHeader("x-request-id", message.getRequestId());
            return msg;
        });
        log.info("[requestId={}] 태깅 요청 발행: jobId={}, documentId={}",
                message.getRequestId(), message.getJobId(), message.getDocumentId());
    }
}
```

### 2.5 Consumer (메시지 소비)

```java
@Component
@Slf4j
public class TaggingMessageConsumer {

    private final TaggingPipelineService pipelineService;

    public TaggingMessageConsumer(TaggingPipelineService pipelineService) {
        this.pipelineService = pipelineService;
    }

    /**
     * RabbitMQ 태깅 큐에서 메시지를 소비하여 OCR/태깅 파이프라인을 실행한다.
     * - Manual ACK: 처리 완료 후 ACK, 실패 시 NACK (DLQ로 이동)
     */
    @RabbitListener(queues = "tagging.queue", ackMode = "MANUAL")
    public void consume(TaggingMessage message, Channel channel,
                        @Header(AmqpHeaders.DELIVERY_TAG) long deliveryTag) {
        log.info("[requestId={}] 태깅 메시지 수신: jobId={}",
                message.getRequestId(), message.getJobId());
        try {
            pipelineService.execute(message);
            channel.basicAck(deliveryTag, false);
            log.info("[requestId={}] 태깅 처리 완료: jobId={}",
                    message.getRequestId(), message.getJobId());
        } catch (Exception e) {
            log.error("[requestId={}] 태깅 처리 실패: jobId={}, error={}",
                    message.getRequestId(), message.getJobId(), e.getMessage());
            try {
                // requeue=false → DLQ로 이동
                channel.basicNack(deliveryTag, false, false);
            } catch (IOException ioException) {
                log.error("NACK 전송 실패", ioException);
            }
        }
    }
}
```

### 2.6 RabbitMQ 설정

```yaml
# application.yml
spring:
  rabbitmq:
    host: localhost
    port: 5672
    username: ${RABBITMQ_USER:smartdocs}
    password: ${RABBITMQ_PASS}
    listener:
      simple:
        acknowledge-mode: manual
        prefetch-count: 1
        concurrency: 1
        max-concurrency: 3
        retry:
          enabled: false    # 재시도는 DLQ로 위임
```

---

## 3. AI 서버 HTTP API 연동

### 3.1 AI 서버 개요

AI 서버는 VLAN 30 (AI망)에 위치하며, OCR과 태깅 두 가지 FastAPI 서비스를 제공한다. DB나 메시지 큐에 직접 접근하지 않는 **stateless** 추론 서버이다.

| 서비스 | 포트 | 프레임워크 | 역할 |
|--------|------|-----------|------|
| **OCR 서비스** | 8001 | FastAPI + Tesseract | PDF/이미지에서 텍스트 추출 |
| **태깅 서비스** | 8000 | FastAPI + KoBERT | 텍스트 기반 문서 분류/태그 예측 |

### 3.2 OCR API

#### Request

```
POST http://dev-ai-worker-01:8001/ocr
Content-Type: application/json
```

```json
{
  "storage_key": "dept-a/2026/02/10/7c9e6679.pdf",
  "document_type": "pdf"
}
```

| 필드 | 타입 | 필수 | 설명 |
|------|------|------|------|
| storage_key | String | O | NFS 파일 상대 경로 |
| document_type | String | O | 파일 유형 (pdf, docx, hwp 등) |

#### Response (성공)

```json
{
  "status": "success",
  "extracted_text": "이 문서는 2026년도 예산 집행 계획에 관한...",
  "page_count": 5,
  "processing_time_ms": 3200
}
```

#### Response (실패)

```json
{
  "status": "error",
  "error_code": "OCR_EXTRACTION_FAILED",
  "error_message": "지원하지 않는 파일 형식입니다"
}
```

### 3.3 태깅 API

#### Request

```
POST http://dev-ai-worker-01:8000/predict
Content-Type: application/json
```

```json
{
  "text": "이 문서는 2026년도 예산 집행 계획에 관한...",
  "top_k": 5
}
```

| 필드 | 타입 | 필수 | 설명 |
|------|------|------|------|
| text | String | O | 분류할 텍스트 (OCR 결과 또는 직접 입력 텍스트) |
| top_k | Integer | X | 반환할 상위 태그 개수 (기본값: 5) |

#### Response (성공)

```json
{
  "status": "success",
  "tags": [
    { "name": "예산", "confidence": 0.9521 },
    { "name": "계획서", "confidence": 0.8734 },
    { "name": "재정", "confidence": 0.7102 }
  ],
  "model_version": "kobert-v1.0",
  "processing_time_ms": 1500
}
```

#### Response (실패)

```json
{
  "status": "error",
  "error_code": "PREDICTION_FAILED",
  "error_message": "입력 텍스트가 비어있습니다"
}
```

### 3.4 OcrClient 구현

```java
/** AI 서버 OCR API를 호출하는 HTTP 클라이언트. */
@Component
@Slf4j
public class OcrClient {

    private final RestClient restClient;

    public OcrClient(@Value("${ai.ocr.url}") String ocrUrl) {
        this.restClient = RestClient.builder()
                .baseUrl(ocrUrl)
                .defaultHeader(HttpHeaders.CONTENT_TYPE, MediaType.APPLICATION_JSON_VALUE)
                .build();
    }

    /**
     * OCR 텍스트 추출 요청.
     * @param storageKey NFS 파일 상대 경로
     * @param documentType 파일 유형
     * @return 추출된 텍스트
     * @throws AiServerException OCR 처리 실패 시
     */
    public OcrResponse extractText(String storageKey, String documentType) {
        OcrRequest request = new OcrRequest(storageKey, documentType);

        return restClient.post()
                .uri("/ocr")
                .body(request)
                .retrieve()
                .body(OcrResponse.class);
    }
}
```

### 3.5 TaggingClient 구현

```java
/** AI 서버 태깅 API를 호출하는 HTTP 클라이언트. */
@Component
@Slf4j
public class TaggingClient {

    private final RestClient restClient;

    public TaggingClient(@Value("${ai.tagging.url}") String taggingUrl) {
        this.restClient = RestClient.builder()
                .baseUrl(taggingUrl)
                .defaultHeader(HttpHeaders.CONTENT_TYPE, MediaType.APPLICATION_JSON_VALUE)
                .build();
    }

    /**
     * 태깅(문서 분류) 요청.
     * @param text 분류할 텍스트
     * @param topK 상위 태그 개수
     * @return 태그 예측 결과
     * @throws AiServerException 태깅 처리 실패 시
     */
    public TaggingResponse predict(String text, int topK) {
        TaggingRequest request = new TaggingRequest(text, topK);

        return restClient.post()
                .uri("/predict")
                .body(request)
                .retrieve()
                .body(TaggingResponse.class);
    }
}
```

### 3.6 AI 서버 연동 설정

```yaml
# application.yml
ai:
  ocr:
    url: http://dev-ai-worker-01:8001
    timeout: 60000       # OCR 타임아웃 60초
  tagging:
    url: http://dev-ai-worker-01:8000
    timeout: 30000       # 태깅 타임아웃 30초
  pipeline:
    timeout: 120000      # 전체 파이프라인 타임아웃 120초
```

### 3.7 document_type별 OCR 분기 로직

| document_type | OCR 호출 | 설명 |
|---------------|---------|------|
| `text` | **스킵** | 사용자가 직접 입력한 텍스트 → contentText 사용 |
| `txt` | **스킵** | 텍스트 파일 → NFS에서 직접 읽기 |
| `pdf` | **호출** | PDF 문서 → OCR로 텍스트 추출 |
| `docx` | **호출** | Word 문서 → OCR로 텍스트 추출 |
| `hwp` | **호출** | 한글 문서 → OCR로 텍스트 추출 |

---

## 4. NFS 파일 스토리지 연동

### 4.1 NFS 연동 개요

| 항목 | 설정 |
|------|------|
| **프로토콜** | NFS (공유 파일시스템) |
| **마운트 포인트** | `/mnt/documents` |
| **NFS 서버** | `10.0.50.x:2049` (CephFS 기반) |
| **파일 경로** | `{tenantId}/{yyyy}/{MM}/{dd}/{documentId}.{ext}` |
| **위치** | VLAN 50 (스토리지망) |
| **마운트 옵션** | `soft,timeo=30,retrans=3` |

### 4.2 디렉토리 구조

```
/mnt/documents/                  # NFS 마운트 포인트
├── dept-a/                      # 부서 A 전용 디렉토리
│   └── 2026/02/10/
│       ├── 7c9e6679.pdf         # 문서 원본
│       └── 7c9e6679-ocr.txt     # OCR 추출 텍스트
│
├── dept-b/                      # 부서 B 전용 디렉토리
│   └── 2026/02/10/
│       └── ...
│
├── dept-c/                      # 부서 C 전용 디렉토리
│   └── 2026/02/10/
│       └── ...
│
└── temp/                        # 업로드 임시 디렉토리
```

### 4.3 NFS 설정

```yaml
# application.yml
storage:
  file:
    base-path: /mnt/documents
    temp-path: /mnt/documents/temp
```

### 4.4 테넌트별 격리

| 격리 수준 | 방식 | 설명 |
|----------|------|------|
| **디렉토리 분리** | 테넌트별 전용 디렉토리 | `/mnt/documents/dept-a`, `/mnt/documents/dept-b`, ... |
| **접근 제어** | 앱 레벨 RBAC | DepartmentFilter + DepartmentContext 기반 접근 제어 |
| **앱 레벨** | TenantContext | 요청 시 tenantId 기반으로 디렉토리 자동 선택 |

---

## 5. 전체 처리 흐름

### 5.1 문서 업로드 → 태깅 흐름 (파일 업로드)

```
① 사용자 → POST /api/documents (file + title)
   │
② App 서버: 파일 → NFS 저장
   │         문서 메타데이터 → MariaDB 저장 (status: PENDING)
   │         TaggingJob 생성 → MariaDB 저장 (status: PENDING)
   │
③ App 서버: TaggingMessage → RabbitMQ 발행
   │
④ Spring AMQP Consumer: 메시지 수신
   │         TaggingJob 상태 → PROCESSING
   │
⑤ Consumer → AI 서버 OCR (:8001)
   │         (document_type이 pdf/docx/hwp인 경우)
   │         OCR 결과 텍스트 → NFS 저장 ({documentId}-ocr.txt)
   │
⑥ Consumer → AI 서버 태깅 (:8000)
   │         텍스트 → KoBERT 분류 → 태그 목록 반환
   │
⑦ Consumer: 태그 결과 → MariaDB 저장 (tags 테이블)
   │         문서 상태 → COMPLETED
   │         TaggingJob 상태 → COMPLETED
   │
⑧ 사용자 → GET /api/documents/{id} (status: COMPLETED 확인)
   사용자 → GET /api/documents/{id}/tags (태그 조회)
```

### 5.2 텍스트 작성 → 태깅 흐름

```
① 사용자 → POST /api/documents (title + content)
   │
② App 서버: content → .txt 파일로 변환 → NFS 저장
   │         문서 메타데이터 → MariaDB 저장 (status: PENDING, document_type: text)
   │         content_text → documents 테이블에 저장
   │         TaggingJob 생성
   │
③ App 서버: TaggingMessage (contentText 포함) → RabbitMQ 발행
   │
④ Spring AMQP Consumer: 메시지 수신
   │         document_type == "text" → OCR 스킵
   │
⑤ Consumer → AI 서버 태깅 (:8000)
   │         contentText → KoBERT 분류
   │
⑥ Consumer: 태그 결과 → MariaDB 저장
   │         상태 → COMPLETED
```

### 5.3 사전 태깅 모드 (tags 파라미터 전달 시)

사전에 태깅된 학습 데이터를 일괄 업로드할 때 사용하는 흐름이다. `POST /api/documents` 요청에 `tags` 파라미터가 포함되면 AI 태깅 파이프라인을 건너뛰고 태그를 즉시 저장한다.

```
① 사용자 → POST /api/documents (file/content + tags)
   │
② App 서버: 파일/텍스트 → NFS 저장
   │         문서 메타데이터 → MariaDB 저장 (status: COMPLETED)
   │
③ App 서버: tags 목록 → MariaDB tags 테이블에 즉시 저장
   │         source = 'IMPORT', confidence = 1.0, model_version = NULL
   │
④ 완료 (Job 생성 없음, RabbitMQ 발행 없음)
```

**일반 업로드와의 차이점:**

| 항목 | 일반 업로드 (tags 미전달) | 사전 태깅 (tags 전달) |
|------|----------------------|-------------------|
| taggingStatus | `PENDING` → `COMPLETED` | 즉시 `COMPLETED` |
| TaggingJob 생성 | O | X |
| RabbitMQ 발행 | O | X |
| AI 서버 호출 | O (OCR + 태깅) | X |
| tags.source | `AI` | `IMPORT` |
| tags.confidence | AI 모델 예측값 (0.0~1.0) | `1.0` (확정) |
| tags.model_version | AI 모델 버전 (예: kobert-v1.0) | `NULL` |

### 5.4 TaggingPipelineService 구현

```java
/** OCR → 태깅 → 결과 저장 파이프라인을 실행하는 서비스. */
@Service
@Slf4j
public class TaggingPipelineService {

    private final OcrClient ocrClient;
    private final TaggingClient taggingClient;
    private final TaggingJobRepository jobRepository;
    private final TagRepository tagRepository;
    private final DocumentRepository documentRepository;
    private final FileStorageService fileStorageService;

    // 생성자 주입 (생략)

    /**
     * 태깅 파이프라인 실행.
     * 1. Job 상태 → PROCESSING
     * 2. document_type에 따라 OCR 호출 또는 스킵
     * 3. 태깅 API 호출
     * 4. 결과 저장 (DB + NFS)
     * 5. Job/Document 상태 → COMPLETED
     */
    @Transactional
    public void execute(TaggingMessage message) {
        // 1. Job 상태 업데이트
        jobRepository.updateStatus(message.getJobId(), JobStatus.PROCESSING);

        try {
            // 2. 텍스트 준비 (OCR 또는 직접 텍스트)
            String text = resolveText(message);

            // 3. 태깅 API 호출
            TaggingResponse taggingResult = taggingClient.predict(text, 5);

            // 4. 태그 결과 DB 저장
            List<TagEntity> tags = taggingResult.getTags().stream()
                    .map(t -> TagEntity.builder()
                            .documentId(message.getDocumentId())
                            .tenantId(message.getTenantId())
                            .name(t.getName())
                            .confidence(t.getConfidence())
                            .source(TagSource.AI)
                            .modelVersion(taggingResult.getModelVersion())
                            .build())
                    .toList();
            tagRepository.saveAll(tags);

            // 5. 상태 업데이트
            documentRepository.updateTaggingStatus(message.getDocumentId(), TaggingStatus.COMPLETED);
            jobRepository.complete(message.getJobId(), taggingResult.getModelVersion());

        } catch (Exception e) {
            documentRepository.updateTaggingStatus(message.getDocumentId(), TaggingStatus.FAILED);
            jobRepository.fail(message.getJobId(), e.getMessage());
            throw e;
        }
    }

    private String resolveText(TaggingMessage message) {
        String type = message.getDocumentType();

        // 텍스트 직접 입력인 경우 OCR 스킵
        if ("text".equals(type)) {
            return message.getContentText();
        }

        // txt 파일인 경우 NFS에서 직접 읽기
        if ("txt".equals(type)) {
            return fileStorageService.readText(message.getTenantId(), message.getStorageKey());
        }

        // pdf, docx, hwp 등은 OCR 호출
        OcrResponse ocrResult = ocrClient.extractText(
                message.getStorageKey(), message.getDocumentType());

        // OCR 결과를 NFS에 저장
        String ocrKey = message.getStorageKey().replaceFirst("\\.[^.]+$", "-ocr.txt");
        fileStorageService.saveText(message.getTenantId(), ocrKey, ocrResult.getExtractedText());

        return ocrResult.getExtractedText();
    }
}
```

---

## 6. 장애 처리 및 복구

### 6.1 장애 시나리오별 처리

| 장애 시나리오 | 처리 방식 | 결과 |
|-------------|----------|------|
| AI 서버 OCR 타임아웃 (60초) | Exception → Job FAILED | 사용자가 Job 재실행 가능 |
| AI 서버 태깅 타임아웃 (30초) | Exception → Job FAILED | 사용자가 Job 재실행 가능 |
| AI 서버 다운 | Circuit Breaker OPEN → 즉시 실패 | DLQ 이동, 복구 후 재처리 |
| RabbitMQ 장애 | Producer 발행 실패 → 문서는 저장됨 (PENDING) | 수동 Job 재등록 가능 |
| MariaDB 장애 | 트랜잭션 실패 → NACK → DLQ | 복구 후 DLQ 재처리 |
| NFS 장애 | 파일 저장 실패 → 업로드 자체 실패 | 사용자에게 즉시 에러 반환 |

### 6.2 Circuit Breaker 설정

AI 서버(OCR/태깅)에 대한 Circuit Breaker를 적용하여 장애 전파를 방지한다.

| 항목 | OCR 서비스 | 태깅 서비스 |
|------|-----------|-----------|
| **대상** | `http://dev-ai-worker-01:8001` | `http://dev-ai-worker-01:8000` |
| **실패 임계값** | 5회 연속 실패 | 5회 연속 실패 |
| **Open 지속 시간** | 30초 | 30초 |
| **Half-Open 요청** | 1회 | 1회 |

### 6.3 DLQ 재처리

태깅 처리에 실패한 메시지는 DLQ(`tagging.dlq`)로 이동한다. 운영자가 장애 원인을 해결한 후 DLQ 메시지를 수동으로 원래 큐로 재발행한다.

```
[장애 발생]
   │
   ▼
tagging.queue → 처리 실패 → NACK (requeue=false)
   │
   ▼
tagging.dlq (Dead Letter Queue)
   │
   ▼
[운영자] 장애 원인 해결 후 DLQ 메시지 재발행 → tagging.queue
```

### 6.4 타임아웃 설정 요약

| 구간 | 타임아웃 | 설명 |
|------|---------|------|
| OCR API 호출 | 60초 | PDF/이미지 OCR 처리 시간 고려 |
| 태깅 API 호출 | 30초 | KoBERT 추론 시간 (CPU 기반) |
| 전체 파이프라인 | 120초 | OCR + 태깅 + DB/NFS 저장 전체 |
| RabbitMQ Consumer | 300초 | 메시지 처리 타임아웃 |

---

## 변경 이력

| 버전 | 날짜 | 변경 내용 | 작성자 |
|------|------|----------|--------|
| 1.0 | 2026-02-09 | 초안 작성: pika Consumer + Callback 구조 | - |
| 2.0 | 2026-02-10 | 전면 재작성: Spring AMQP Consumer로 전환, AI 서버 HTTP API 연동, 콜백 제거, VLAN 재설계 반영 | - |

---

## 관련 문서

- [07_백엔드_설계서.md](07_백엔드_설계서.md) - 백엔드 설계서 (상위 문서)
- [07-1_API_설계서.md](07-1_API_설계서.md) - API 설계서
- [07-2_데이터베이스_설계서.md](07-2_데이터베이스_설계서.md) - 데이터베이스 설계서
- [06_스토리지_설계서.md](06_스토리지_설계서.md) - 스토리지 설계서 (NFS)
- [05_네트워크_보안_설계서.md](05_네트워크_보안_설계서.md) - 네트워크/보안 설계서
